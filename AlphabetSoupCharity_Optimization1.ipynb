{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deliverable 3: Optimize the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Up to this point, the accuracy from the existing model has an accuracy of 72.56%. The goal is to increase accuracy above 75%. From the initial file, the following changes have already been made prior to the application_df file:\n",
    "- Application Type has been binned to group all application types with under 200 value counts\n",
    "- Classification has been binned to group all classifications with under 1000 value counts\n",
    "- Categorical data has been encoded with OneHotEncoder\n",
    "\n",
    "One observation: there are 8747 unique values in the Ask Amount column, which are likely posing a major problem, for the neural networks since it doesn't interpret the numbers as sequential, but rather as just unique values. This column should either be removed or binned into groups. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\justi\\anaconda3\\envs\\mlenv\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATUS</th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>APPLICATION_TYPE_Other</th>\n",
       "      <th>APPLICATION_TYPE_T10</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>APPLICATION_TYPE_T4</th>\n",
       "      <th>APPLICATION_TYPE_T5</th>\n",
       "      <th>APPLICATION_TYPE_T6</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>108590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>5000</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>6692</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>142590</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATUS  ASK_AMT  IS_SUCCESSFUL  APPLICATION_TYPE_Other  \\\n",
       "0       1     5000              1                     0.0   \n",
       "1       1   108590              1                     0.0   \n",
       "2       1     5000              0                     0.0   \n",
       "3       1     6692              1                     0.0   \n",
       "4       1   142590              1                     0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T10  APPLICATION_TYPE_T19  APPLICATION_TYPE_T3  \\\n",
       "0                   1.0                   0.0                  0.0   \n",
       "1                   0.0                   0.0                  1.0   \n",
       "2                   0.0                   0.0                  0.0   \n",
       "3                   0.0                   0.0                  1.0   \n",
       "4                   0.0                   0.0                  1.0   \n",
       "\n",
       "   APPLICATION_TYPE_T4  APPLICATION_TYPE_T5  APPLICATION_TYPE_T6  ...  \\\n",
       "0                  0.0                  0.0                  0.0  ...   \n",
       "1                  0.0                  0.0                  0.0  ...   \n",
       "2                  0.0                  1.0                  0.0  ...   \n",
       "3                  0.0                  0.0                  0.0  ...   \n",
       "4                  0.0                  0.0                  0.0  ...   \n",
       "\n",
       "   INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n",
       "0                0.0                     0.0                       0.0   \n",
       "1                1.0                     0.0                       0.0   \n",
       "2                0.0                     0.0                       0.0   \n",
       "3                0.0                     1.0                       0.0   \n",
       "4                0.0                     0.0                       1.0   \n",
       "\n",
       "   INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
       "0                 0.0               0.0                     0.0   \n",
       "1                 0.0               0.0                     0.0   \n",
       "2                 0.0               0.0                     0.0   \n",
       "3                 0.0               0.0                     0.0   \n",
       "4                 0.0               0.0                     0.0   \n",
       "\n",
       "   INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  \\\n",
       "0              0.0                0.0                       1.0   \n",
       "1              0.0                0.0                       1.0   \n",
       "2              0.0                0.0                       1.0   \n",
       "3              0.0                0.0                       1.0   \n",
       "4              0.0                0.0                       1.0   \n",
       "\n",
       "   SPECIAL_CONSIDERATIONS_Y  \n",
       "0                       0.0  \n",
       "1                       0.0  \n",
       "2                       0.0  \n",
       "3                       0.0  \n",
       "4                       0.0  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import our dependencies\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from pathlib import Path\n",
    "import kerastuner as kt\n",
    "\n",
    "#  Import and read the charity_data.csv.\n",
    "application_df = pd.read_csv(\"Resources/application_df.csv\")\n",
    "application_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000        25398\n",
       "10478           3\n",
       "15583           3\n",
       "63981           3\n",
       "6725            3\n",
       "            ...  \n",
       "5371754         1\n",
       "30060           1\n",
       "43091152        1\n",
       "18683           1\n",
       "36500179        1\n",
       "Name: ASK_AMT, Length: 8747, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ask_counts = application_df.ASK_AMT.value_counts()\n",
    "ask_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just binning by frequency poses a problem because aside from $5000, most others asked for individualized amounts, so ranges will need to be made"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min: 5000, Median: 5000.0, Max: 8597806340\n"
     ]
    }
   ],
   "source": [
    "min_ask = application_df.ASK_AMT.min()\n",
    "max_ask = application_df.ASK_AMT.max()\n",
    "median_ask = application_df.ASK_AMT.median()\n",
    "\n",
    "print(f'Min: {min_ask}, Median: {median_ask}, Max: {max_ask}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is heavily skewed to the right with values ranging from $5000 to $8.6 billion.  The following steps were used to determine good amounts to get similarly sized bins for effective learning outside of the '5000' bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000    25398\n",
       "Name: ASK_AMT, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "five_thousand = application_df.ASK_AMT[application_df.ASK_AMT == 5000]\n",
    "five_thousand.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2185"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "under_thirtyfive = application_df.ASK_AMT[(application_df.ASK_AMT > 5000) & (application_df.ASK_AMT < 35000)]\n",
    "under_thirtyfive.nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2044"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "under_hundred = application_df.ASK_AMT[(application_df.ASK_AMT > 35000) & (application_df.ASK_AMT < 100000)]\n",
    "under_hundred.nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2289"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "under_fivehundred = application_df.ASK_AMT[(\n",
    "    application_df.ASK_AMT > 100000) & (application_df.ASK_AMT < 500000)]\n",
    "under_fivehundred.nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2226"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "over_halfmillion = application_df.ASK_AMT[application_df.ASK_AMT > 500000]\n",
    "over_halfmillion.nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the bins, labeling with the arbitrary 1-5 categories for the network learning\n",
    "bins = [0, 5000, 35000, 100000, 500000, max_ask]\n",
    "labels = [1, 2, 3, 4, 5]\n",
    "\n",
    "application_df[\"ASK_BIN\"] = pd.cut(application_df[\"ASK_AMT\"], bins=bins, labels=labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASK_AMT</th>\n",
       "      <th>ASK_BIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>108590</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6692</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142590</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>31452</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7508025</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>94389</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ASK_AMT ASK_BIN\n",
       "0     5000       1\n",
       "1   108590       4\n",
       "2     5000       1\n",
       "3     6692       2\n",
       "4   142590       4\n",
       "5     5000       1\n",
       "6    31452       2\n",
       "7  7508025       5\n",
       "8    94389       3\n",
       "9     5000       1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "application_df[[\"ASK_AMT\",\"ASK_BIN\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    25398\n",
       "4     2304\n",
       "2     2283\n",
       "5     2227\n",
       "3     2087\n",
       "Name: ASK_BIN, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verify the same value counts as planned - if true, then remove the ASK_AMT column \n",
    "application_df[\"ASK_BIN\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATUS</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>APPLICATION_TYPE_Other</th>\n",
       "      <th>APPLICATION_TYPE_T10</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>APPLICATION_TYPE_T4</th>\n",
       "      <th>APPLICATION_TYPE_T5</th>\n",
       "      <th>APPLICATION_TYPE_T6</th>\n",
       "      <th>APPLICATION_TYPE_T7</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_N</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "      <th>ASK_BIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 44 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATUS  IS_SUCCESSFUL  APPLICATION_TYPE_Other  APPLICATION_TYPE_T10  \\\n",
       "0       1              1                     0.0                   1.0   \n",
       "1       1              1                     0.0                   0.0   \n",
       "2       1              0                     0.0                   0.0   \n",
       "3       1              1                     0.0                   0.0   \n",
       "4       1              1                     0.0                   0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T19  APPLICATION_TYPE_T3  APPLICATION_TYPE_T4  \\\n",
       "0                   0.0                  0.0                  0.0   \n",
       "1                   0.0                  1.0                  0.0   \n",
       "2                   0.0                  0.0                  0.0   \n",
       "3                   0.0                  1.0                  0.0   \n",
       "4                   0.0                  1.0                  0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T5  APPLICATION_TYPE_T6  APPLICATION_TYPE_T7  ...  \\\n",
       "0                  0.0                  0.0                  0.0  ...   \n",
       "1                  0.0                  0.0                  0.0  ...   \n",
       "2                  1.0                  0.0                  0.0  ...   \n",
       "3                  0.0                  0.0                  0.0  ...   \n",
       "4                  0.0                  0.0                  0.0  ...   \n",
       "\n",
       "   INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  INCOME_AMT_10M-50M  \\\n",
       "0                     0.0                       0.0                 0.0   \n",
       "1                     0.0                       0.0                 0.0   \n",
       "2                     0.0                       0.0                 0.0   \n",
       "3                     1.0                       0.0                 0.0   \n",
       "4                     0.0                       1.0                 0.0   \n",
       "\n",
       "   INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  INCOME_AMT_50M+  \\\n",
       "0               0.0                     0.0              0.0   \n",
       "1               0.0                     0.0              0.0   \n",
       "2               0.0                     0.0              0.0   \n",
       "3               0.0                     0.0              0.0   \n",
       "4               0.0                     0.0              0.0   \n",
       "\n",
       "   INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_N  SPECIAL_CONSIDERATIONS_Y  \\\n",
       "0                0.0                       1.0                       0.0   \n",
       "1                0.0                       1.0                       0.0   \n",
       "2                0.0                       1.0                       0.0   \n",
       "3                0.0                       1.0                       0.0   \n",
       "4                0.0                       1.0                       0.0   \n",
       "\n",
       "   ASK_BIN  \n",
       "0        1  \n",
       "1        4  \n",
       "2        1  \n",
       "3        2  \n",
       "4        4  \n",
       "\n",
       "[5 rows x 44 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "application_df = application_df.drop(columns=\"ASK_AMT\")\n",
    "application_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "STATUS                          2\n",
       "IS_SUCCESSFUL                   2\n",
       "APPLICATION_TYPE_Other          2\n",
       "APPLICATION_TYPE_T10            2\n",
       "APPLICATION_TYPE_T19            2\n",
       "APPLICATION_TYPE_T3             2\n",
       "APPLICATION_TYPE_T4             2\n",
       "APPLICATION_TYPE_T5             2\n",
       "APPLICATION_TYPE_T6             2\n",
       "APPLICATION_TYPE_T7             2\n",
       "APPLICATION_TYPE_T8             2\n",
       "AFFILIATION_CompanySponsored    2\n",
       "AFFILIATION_Family/Parent       2\n",
       "AFFILIATION_Independent         2\n",
       "AFFILIATION_National            2\n",
       "AFFILIATION_Other               2\n",
       "AFFILIATION_Regional            2\n",
       "CLASSIFICATION_C1000            2\n",
       "CLASSIFICATION_C1200            2\n",
       "CLASSIFICATION_C2000            2\n",
       "CLASSIFICATION_C2100            2\n",
       "CLASSIFICATION_C3000            2\n",
       "CLASSIFICATION_Other            2\n",
       "USE_CASE_CommunityServ          2\n",
       "USE_CASE_Heathcare              2\n",
       "USE_CASE_Other                  2\n",
       "USE_CASE_Preservation           2\n",
       "USE_CASE_ProductDev             2\n",
       "ORGANIZATION_Association        2\n",
       "ORGANIZATION_Co-operative       2\n",
       "ORGANIZATION_Corporation        2\n",
       "ORGANIZATION_Trust              2\n",
       "INCOME_AMT_0                    2\n",
       "INCOME_AMT_1-9999               2\n",
       "INCOME_AMT_10000-24999          2\n",
       "INCOME_AMT_100000-499999        2\n",
       "INCOME_AMT_10M-50M              2\n",
       "INCOME_AMT_1M-5M                2\n",
       "INCOME_AMT_25000-99999          2\n",
       "INCOME_AMT_50M+                 2\n",
       "INCOME_AMT_5M-10M               2\n",
       "SPECIAL_CONSIDERATIONS_N        2\n",
       "SPECIAL_CONSIDERATIONS_Y        2\n",
       "ASK_BIN                         5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the number of unique values in all of the parameters to ensure they are all under 10\n",
    "application_df.nunique()\n",
    "\n",
    "# all are n=2 except the ASK_BIN which is now 5, substantially less than the 8747 it started with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='Density'>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ask_bin_counts = application_df.ASK_BIN.value_counts()\n",
    "ask_bin_counts.plot.density()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Special Considerations columns are redundant and one should be dropped\n",
    "application_df = application_df.drop(columns=\"SPECIAL_CONSIDERATIONS_N\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate Sets and Training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_trainer(df):\n",
    "    # Remove the outcome and set up the training model\n",
    "    y = df.IS_SUCCESSFUL\n",
    "    X = df.drop(columns=\"IS_SUCCESSFUL\")\n",
    "\n",
    "    # Split the preprocessed data into a training and testing dataset, values are not balanced - apply stratification\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, random_state=512, stratify=y)\n",
    "\n",
    "    # Scale the data\n",
    "    scaler = StandardScaler()\n",
    "    X_scaler = scaler.fit(X_train)\n",
    "    X_train_scaled = X_scaler.transform(X_train)\n",
    "    X_test_scaled = X_scaler.transform(X_test)\n",
    "\n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled, X_test_scaled, y_train, y_test = df_trainer(application_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using the same model as the original analysis after basketing the ask amounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 80)                3440      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 30)                2430      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 1)                 31        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,901\n",
      "Trainable params: 5,901\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
    "number_input_features = len(X_train_scaled[0])\n",
    "hidden_layer1 = 80\n",
    "hidden_layer2 = 30\n",
    "\n",
    "nn = tf.keras.models.Sequential()\n",
    "\n",
    "# First hidden layer\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_layer1,\n",
    "       input_dim=number_input_features, activation='relu'))\n",
    "\n",
    "# Second hidden layer\n",
    "\n",
    "nn.add(tf.keras.layers.Dense(units=hidden_layer2, activation='relu'))\n",
    "\n",
    "# Output layer\n",
    "nn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))\n",
    "\n",
    "# Check the structure of the model\n",
    "nn.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Checkpoint Path and filenames\n",
    "os.makedirs(\"checkpoints_2/\", exist_ok=True)\n",
    "checkpoint_path = \"checkpoints_2/weights.{epoch:02d}.hdf5\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "nn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Create a callback that saves the model's weights every 5 epochs\n",
    "cp_callback = ModelCheckpoint(\n",
    "    filepath=checkpoint_path,\n",
    "    verbose=1,\n",
    "    save_weights_only=True,\n",
    "    save_freq=5\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "  1/804 [..............................] - ETA: 5:23 - loss: 0.7571 - accuracy: 0.3750\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      " 15/804 [..............................] - ETA: 2s - loss: 0.6976 - accuracy: 0.5000  \n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      " 35/804 [>.............................] - ETA: 2s - loss: 0.6636 - accuracy: 0.6116\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      " 55/804 [=>............................] - ETA: 2s - loss: 0.6388 - accuracy: 0.6534\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      " 75/804 [=>............................] - ETA: 2s - loss: 0.6264 - accuracy: 0.6654\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      " 94/804 [==>...........................] - ETA: 2s - loss: 0.6194 - accuracy: 0.6725\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "110/804 [===>..........................] - ETA: 2s - loss: 0.6169 - accuracy: 0.6761\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "130/804 [===>..........................] - ETA: 2s - loss: 0.6076 - accuracy: 0.6856\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "149/804 [====>.........................] - ETA: 1s - loss: 0.6084 - accuracy: 0.6867\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "165/804 [=====>........................] - ETA: 1s - loss: 0.6010 - accuracy: 0.6939\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "185/804 [=====>........................] - ETA: 1s - loss: 0.5987 - accuracy: 0.6956\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "205/804 [======>.......................] - ETA: 1s - loss: 0.5946 - accuracy: 0.6991\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "224/804 [=======>......................] - ETA: 1s - loss: 0.5936 - accuracy: 0.7019\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "240/804 [=======>......................] - ETA: 1s - loss: 0.5903 - accuracy: 0.7042\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "258/804 [========>.....................] - ETA: 1s - loss: 0.5886 - accuracy: 0.7058\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "275/804 [=========>....................] - ETA: 1s - loss: 0.5881 - accuracy: 0.7066\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "295/804 [==========>...................] - ETA: 1s - loss: 0.5860 - accuracy: 0.7081\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "315/804 [==========>...................] - ETA: 1s - loss: 0.5851 - accuracy: 0.7093\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "334/804 [===========>..................] - ETA: 1s - loss: 0.5841 - accuracy: 0.7091\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "350/804 [============>.................] - ETA: 1s - loss: 0.5827 - accuracy: 0.7100\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "370/804 [============>.................] - ETA: 1s - loss: 0.5793 - accuracy: 0.7126\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "390/804 [=============>................] - ETA: 1s - loss: 0.5792 - accuracy: 0.7121\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "410/804 [==============>...............] - ETA: 1s - loss: 0.5796 - accuracy: 0.7120\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "430/804 [===============>..............] - ETA: 1s - loss: 0.5792 - accuracy: 0.7127\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "450/804 [===============>..............] - ETA: 1s - loss: 0.5773 - accuracy: 0.7141\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "470/804 [================>.............] - ETA: 0s - loss: 0.5769 - accuracy: 0.7146\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "490/804 [=================>............] - ETA: 0s - loss: 0.5759 - accuracy: 0.7152\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "510/804 [==================>...........] - ETA: 0s - loss: 0.5757 - accuracy: 0.7148\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "530/804 [==================>...........] - ETA: 0s - loss: 0.5765 - accuracy: 0.7141\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "550/804 [===================>..........] - ETA: 0s - loss: 0.5756 - accuracy: 0.7145\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "570/804 [====================>.........] - ETA: 0s - loss: 0.5751 - accuracy: 0.7151\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "590/804 [=====================>........] - ETA: 0s - loss: 0.5741 - accuracy: 0.7160\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "606/804 [=====================>........] - ETA: 0s - loss: 0.5735 - accuracy: 0.7164\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "625/804 [======================>.......] - ETA: 0s - loss: 0.5734 - accuracy: 0.7167\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "645/804 [=======================>......] - ETA: 0s - loss: 0.5726 - accuracy: 0.7172\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "665/804 [=======================>......] - ETA: 0s - loss: 0.5727 - accuracy: 0.7172\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "685/804 [========================>.....] - ETA: 0s - loss: 0.5716 - accuracy: 0.7179\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "705/804 [=========================>....] - ETA: 0s - loss: 0.5717 - accuracy: 0.7176\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "725/804 [==========================>...] - ETA: 0s - loss: 0.5713 - accuracy: 0.7174\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "745/804 [==========================>...] - ETA: 0s - loss: 0.5707 - accuracy: 0.7179\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "765/804 [===========================>..] - ETA: 0s - loss: 0.5700 - accuracy: 0.7188\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "785/804 [============================>.] - ETA: 0s - loss: 0.5695 - accuracy: 0.7190\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "\n",
      "Epoch 1: saving model to checkpoints_2\\weights.01.hdf5\n",
      "804/804 [==============================] - 3s 3ms/step - loss: 0.5700 - accuracy: 0.7187\n",
      "Epoch 2/5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "  1/804 [..............................] - ETA: 10s - loss: 0.6102 - accuracy: 0.6562\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      " 21/804 [..............................] - ETA: 2s - loss: 0.5131 - accuracy: 0.7545 \n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      " 41/804 [>.............................] - ETA: 2s - loss: 0.5269 - accuracy: 0.7462\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      " 61/804 [=>............................] - ETA: 2s - loss: 0.5411 - accuracy: 0.7387\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      " 81/804 [==>...........................] - ETA: 2s - loss: 0.5427 - accuracy: 0.7365\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "101/804 [==>...........................] - ETA: 1s - loss: 0.5448 - accuracy: 0.7330\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "121/804 [===>..........................] - ETA: 1s - loss: 0.5464 - accuracy: 0.7322\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "141/804 [====>.........................] - ETA: 1s - loss: 0.5485 - accuracy: 0.7312\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "161/804 [=====>........................] - ETA: 1s - loss: 0.5508 - accuracy: 0.7290\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "181/804 [=====>........................] - ETA: 1s - loss: 0.5514 - accuracy: 0.7288\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "201/804 [======>.......................] - ETA: 1s - loss: 0.5556 - accuracy: 0.7247\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "221/804 [=======>......................] - ETA: 1s - loss: 0.5584 - accuracy: 0.7241\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "238/804 [=======>......................] - ETA: 1s - loss: 0.5564 - accuracy: 0.7262\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "256/804 [========>.....................] - ETA: 1s - loss: 0.5586 - accuracy: 0.7246\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "276/804 [=========>....................] - ETA: 1s - loss: 0.5594 - accuracy: 0.7236\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "296/804 [==========>...................] - ETA: 1s - loss: 0.5596 - accuracy: 0.7236\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "316/804 [==========>...................] - ETA: 1s - loss: 0.5593 - accuracy: 0.7245\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "336/804 [===========>..................] - ETA: 1s - loss: 0.5606 - accuracy: 0.7232\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "356/804 [============>.................] - ETA: 1s - loss: 0.5613 - accuracy: 0.7231\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "376/804 [=============>................] - ETA: 1s - loss: 0.5593 - accuracy: 0.7244\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "396/804 [=============>................] - ETA: 1s - loss: 0.5599 - accuracy: 0.7230\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "416/804 [==============>...............] - ETA: 1s - loss: 0.5590 - accuracy: 0.7240\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "436/804 [===============>..............] - ETA: 1s - loss: 0.5587 - accuracy: 0.7243\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "456/804 [================>.............] - ETA: 1s - loss: 0.5588 - accuracy: 0.7246\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "476/804 [================>.............] - ETA: 0s - loss: 0.5582 - accuracy: 0.7247\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "496/804 [=================>............] - ETA: 0s - loss: 0.5579 - accuracy: 0.7248\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "516/804 [==================>...........] - ETA: 0s - loss: 0.5566 - accuracy: 0.7255\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "536/804 [===================>..........] - ETA: 0s - loss: 0.5576 - accuracy: 0.7255\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "556/804 [===================>..........] - ETA: 0s - loss: 0.5571 - accuracy: 0.7259\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "576/804 [====================>.........] - ETA: 0s - loss: 0.5576 - accuracy: 0.7256\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "593/804 [=====================>........] - ETA: 0s - loss: 0.5566 - accuracy: 0.7258\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "611/804 [=====================>........] - ETA: 0s - loss: 0.5562 - accuracy: 0.7261\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "631/804 [======================>.......] - ETA: 0s - loss: 0.5551 - accuracy: 0.7270\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "651/804 [=======================>......] - ETA: 0s - loss: 0.5548 - accuracy: 0.7276\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "671/804 [========================>.....] - ETA: 0s - loss: 0.5542 - accuracy: 0.7279\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "691/804 [========================>.....] - ETA: 0s - loss: 0.5540 - accuracy: 0.7277\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "711/804 [=========================>....] - ETA: 0s - loss: 0.5543 - accuracy: 0.7274\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "731/804 [==========================>...] - ETA: 0s - loss: 0.5539 - accuracy: 0.7278\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "751/804 [===========================>..] - ETA: 0s - loss: 0.5541 - accuracy: 0.7277\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "771/804 [===========================>..] - ETA: 0s - loss: 0.5541 - accuracy: 0.7274\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "791/804 [============================>.] - ETA: 0s - loss: 0.5532 - accuracy: 0.7282\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "\n",
      "Epoch 2: saving model to checkpoints_2\\weights.02.hdf5\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5534 - accuracy: 0.7282\n",
      "Epoch 3/5\n",
      "  1/804 [..............................] - ETA: 1s - loss: 0.5744 - accuracy: 0.6875\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      " 17/804 [..............................] - ETA: 2s - loss: 0.5597 - accuracy: 0.7261\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      " 37/804 [>.............................] - ETA: 2s - loss: 0.5573 - accuracy: 0.7289\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      " 54/804 [=>............................] - ETA: 2s - loss: 0.5529 - accuracy: 0.7338\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      " 67/804 [=>............................] - ETA: 2s - loss: 0.5461 - accuracy: 0.7388\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      " 87/804 [==>...........................] - ETA: 2s - loss: 0.5418 - accuracy: 0.7407\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "107/804 [==>...........................] - ETA: 2s - loss: 0.5445 - accuracy: 0.7386\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "127/804 [===>..........................] - ETA: 2s - loss: 0.5439 - accuracy: 0.7404\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "147/804 [====>.........................] - ETA: 2s - loss: 0.5482 - accuracy: 0.7396\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "167/804 [=====>........................] - ETA: 1s - loss: 0.5483 - accuracy: 0.7416\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "187/804 [=====>........................] - ETA: 1s - loss: 0.5492 - accuracy: 0.7405\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "197/804 [======>.......................] - ETA: 1s - loss: 0.5461 - accuracy: 0.7425\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "217/804 [=======>......................] - ETA: 1s - loss: 0.5466 - accuracy: 0.7406\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "237/804 [=======>......................] - ETA: 1s - loss: 0.5474 - accuracy: 0.7385\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "257/804 [========>.....................] - ETA: 1s - loss: 0.5482 - accuracy: 0.7386\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "277/804 [=========>....................] - ETA: 1s - loss: 0.5468 - accuracy: 0.7391\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "297/804 [==========>...................] - ETA: 1s - loss: 0.5484 - accuracy: 0.7370\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "317/804 [==========>...................] - ETA: 1s - loss: 0.5467 - accuracy: 0.7374\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "337/804 [===========>..................] - ETA: 1s - loss: 0.5482 - accuracy: 0.7352\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "357/804 [============>.................] - ETA: 1s - loss: 0.5483 - accuracy: 0.7342\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "377/804 [=============>................] - ETA: 1s - loss: 0.5495 - accuracy: 0.7338\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "397/804 [=============>................] - ETA: 1s - loss: 0.5502 - accuracy: 0.7337\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "417/804 [==============>...............] - ETA: 1s - loss: 0.5497 - accuracy: 0.7337\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "437/804 [===============>..............] - ETA: 1s - loss: 0.5486 - accuracy: 0.7342\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "457/804 [================>.............] - ETA: 1s - loss: 0.5490 - accuracy: 0.7337\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "477/804 [================>.............] - ETA: 0s - loss: 0.5485 - accuracy: 0.7335\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "497/804 [=================>............] - ETA: 0s - loss: 0.5486 - accuracy: 0.7330\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "517/804 [==================>...........] - ETA: 0s - loss: 0.5489 - accuracy: 0.7328\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "537/804 [===================>..........] - ETA: 0s - loss: 0.5487 - accuracy: 0.7335\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "557/804 [===================>..........] - ETA: 0s - loss: 0.5479 - accuracy: 0.7336\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "577/804 [====================>.........] - ETA: 0s - loss: 0.5490 - accuracy: 0.7329\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "597/804 [=====================>........] - ETA: 0s - loss: 0.5498 - accuracy: 0.7327\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "617/804 [======================>.......] - ETA: 0s - loss: 0.5505 - accuracy: 0.7320\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "637/804 [======================>.......] - ETA: 0s - loss: 0.5509 - accuracy: 0.7315\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "657/804 [=======================>......] - ETA: 0s - loss: 0.5512 - accuracy: 0.7310\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "677/804 [========================>.....] - ETA: 0s - loss: 0.5510 - accuracy: 0.7309\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "697/804 [=========================>....] - ETA: 0s - loss: 0.5511 - accuracy: 0.7307\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "717/804 [=========================>....] - ETA: 0s - loss: 0.5511 - accuracy: 0.7307\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "737/804 [==========================>...] - ETA: 0s - loss: 0.5501 - accuracy: 0.7313\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "757/804 [===========================>..] - ETA: 0s - loss: 0.5501 - accuracy: 0.7313\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "777/804 [===========================>..] - ETA: 0s - loss: 0.5507 - accuracy: 0.7311\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "797/804 [============================>.] - ETA: 0s - loss: 0.5503 - accuracy: 0.7313\n",
      "Epoch 3: saving model to checkpoints_2\\weights.03.hdf5\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5498 - accuracy: 0.7317\n",
      "Epoch 4/5\n",
      "  1/804 [..............................] - ETA: 0s - loss: 0.4297 - accuracy: 0.8125\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      " 18/804 [..............................] - ETA: 2s - loss: 0.5686 - accuracy: 0.7222\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      " 38/804 [>.............................] - ETA: 2s - loss: 0.5652 - accuracy: 0.7245\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      " 58/804 [=>............................] - ETA: 2s - loss: 0.5580 - accuracy: 0.7236\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      " 78/804 [=>............................] - ETA: 2s - loss: 0.5535 - accuracy: 0.7272\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      " 98/804 [==>...........................] - ETA: 1s - loss: 0.5534 - accuracy: 0.7267\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "118/804 [===>..........................] - ETA: 1s - loss: 0.5509 - accuracy: 0.7299\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "138/804 [====>.........................] - ETA: 1s - loss: 0.5511 - accuracy: 0.7298\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "158/804 [====>.........................] - ETA: 1s - loss: 0.5517 - accuracy: 0.7296\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "178/804 [=====>........................] - ETA: 1s - loss: 0.5508 - accuracy: 0.7296\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "198/804 [======>.......................] - ETA: 1s - loss: 0.5506 - accuracy: 0.7307\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "218/804 [=======>......................] - ETA: 1s - loss: 0.5502 - accuracy: 0.7312\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "238/804 [=======>......................] - ETA: 1s - loss: 0.5490 - accuracy: 0.7323\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "258/804 [========>.....................] - ETA: 1s - loss: 0.5489 - accuracy: 0.7312\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "278/804 [=========>....................] - ETA: 1s - loss: 0.5467 - accuracy: 0.7331\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "298/804 [==========>...................] - ETA: 1s - loss: 0.5449 - accuracy: 0.7357\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "318/804 [==========>...................] - ETA: 1s - loss: 0.5443 - accuracy: 0.7363\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "338/804 [===========>..................] - ETA: 1s - loss: 0.5448 - accuracy: 0.7359\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "356/804 [============>.................] - ETA: 1s - loss: 0.5461 - accuracy: 0.7348\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "371/804 [============>.................] - ETA: 1s - loss: 0.5461 - accuracy: 0.7355\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "388/804 [=============>................] - ETA: 1s - loss: 0.5445 - accuracy: 0.7361\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "408/804 [==============>...............] - ETA: 1s - loss: 0.5459 - accuracy: 0.7356\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "428/804 [==============>...............] - ETA: 1s - loss: 0.5462 - accuracy: 0.7353\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "448/804 [===============>..............] - ETA: 1s - loss: 0.5468 - accuracy: 0.7351\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "468/804 [================>.............] - ETA: 0s - loss: 0.5466 - accuracy: 0.7351\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "488/804 [=================>............] - ETA: 0s - loss: 0.5461 - accuracy: 0.7353\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "508/804 [=================>............] - ETA: 0s - loss: 0.5457 - accuracy: 0.7354\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "528/804 [==================>...........] - ETA: 0s - loss: 0.5461 - accuracy: 0.7355\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "548/804 [===================>..........] - ETA: 0s - loss: 0.5453 - accuracy: 0.7361\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "568/804 [====================>.........] - ETA: 0s - loss: 0.5470 - accuracy: 0.7350\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "588/804 [====================>.........] - ETA: 0s - loss: 0.5469 - accuracy: 0.7351\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "608/804 [=====================>........] - ETA: 0s - loss: 0.5473 - accuracy: 0.7341\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "628/804 [======================>.......] - ETA: 0s - loss: 0.5471 - accuracy: 0.7339\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "648/804 [=======================>......] - ETA: 0s - loss: 0.5475 - accuracy: 0.7337\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "668/804 [=======================>......] - ETA: 0s - loss: 0.5483 - accuracy: 0.7325\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "688/804 [========================>.....] - ETA: 0s - loss: 0.5486 - accuracy: 0.7321\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "708/804 [=========================>....] - ETA: 0s - loss: 0.5486 - accuracy: 0.7322\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "728/804 [==========================>...] - ETA: 0s - loss: 0.5488 - accuracy: 0.7318\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "748/804 [==========================>...] - ETA: 0s - loss: 0.5492 - accuracy: 0.7315\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "768/804 [===========================>..] - ETA: 0s - loss: 0.5493 - accuracy: 0.7319\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "788/804 [============================>.] - ETA: 0s - loss: 0.5486 - accuracy: 0.7324\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "\n",
      "Epoch 4: saving model to checkpoints_2\\weights.04.hdf5\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5482 - accuracy: 0.7327\n",
      "Epoch 5/5\n",
      "  1/804 [..............................] - ETA: 1s - loss: 0.5735 - accuracy: 0.7500\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      " 16/804 [..............................] - ETA: 2s - loss: 0.5622 - accuracy: 0.7363\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      " 32/804 [>.............................] - ETA: 2s - loss: 0.5539 - accuracy: 0.7354\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      " 49/804 [>.............................] - ETA: 2s - loss: 0.5490 - accuracy: 0.7411\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      " 69/804 [=>............................] - ETA: 2s - loss: 0.5503 - accuracy: 0.7360\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      " 89/804 [==>...........................] - ETA: 2s - loss: 0.5503 - accuracy: 0.7360\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "109/804 [===>..........................] - ETA: 2s - loss: 0.5506 - accuracy: 0.7317\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "129/804 [===>..........................] - ETA: 2s - loss: 0.5564 - accuracy: 0.7250\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "149/804 [====>.........................] - ETA: 1s - loss: 0.5569 - accuracy: 0.7234\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "169/804 [=====>........................] - ETA: 1s - loss: 0.5561 - accuracy: 0.7260\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "189/804 [======>.......................] - ETA: 1s - loss: 0.5561 - accuracy: 0.7264\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "209/804 [======>.......................] - ETA: 1s - loss: 0.5527 - accuracy: 0.7295\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "229/804 [=======>......................] - ETA: 1s - loss: 0.5498 - accuracy: 0.7308\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "249/804 [========>.....................] - ETA: 1s - loss: 0.5495 - accuracy: 0.7309\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "269/804 [=========>....................] - ETA: 1s - loss: 0.5486 - accuracy: 0.7329\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "289/804 [=========>....................] - ETA: 1s - loss: 0.5470 - accuracy: 0.7341\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "309/804 [==========>...................] - ETA: 1s - loss: 0.5495 - accuracy: 0.7324\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "329/804 [===========>..................] - ETA: 1s - loss: 0.5496 - accuracy: 0.7317\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "349/804 [============>.................] - ETA: 1s - loss: 0.5482 - accuracy: 0.7333\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "369/804 [============>.................] - ETA: 1s - loss: 0.5489 - accuracy: 0.7317\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "389/804 [=============>................] - ETA: 1s - loss: 0.5475 - accuracy: 0.7331\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "409/804 [==============>...............] - ETA: 1s - loss: 0.5474 - accuracy: 0.7328\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "428/804 [==============>...............] - ETA: 1s - loss: 0.5469 - accuracy: 0.7330\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "444/804 [===============>..............] - ETA: 1s - loss: 0.5463 - accuracy: 0.7335\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "464/804 [================>.............] - ETA: 1s - loss: 0.5449 - accuracy: 0.7345\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "484/804 [=================>............] - ETA: 0s - loss: 0.5455 - accuracy: 0.7335\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "504/804 [=================>............] - ETA: 0s - loss: 0.5479 - accuracy: 0.7321\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "524/804 [==================>...........] - ETA: 0s - loss: 0.5483 - accuracy: 0.7316\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "544/804 [===================>..........] - ETA: 0s - loss: 0.5480 - accuracy: 0.7325\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "564/804 [====================>.........] - ETA: 0s - loss: 0.5479 - accuracy: 0.7328\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "584/804 [====================>.........] - ETA: 0s - loss: 0.5487 - accuracy: 0.7319\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "604/804 [=====================>........] - ETA: 0s - loss: 0.5483 - accuracy: 0.7326\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "624/804 [======================>.......] - ETA: 0s - loss: 0.5492 - accuracy: 0.7321\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "644/804 [=======================>......] - ETA: 0s - loss: 0.5481 - accuracy: 0.7331\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "664/804 [=======================>......] - ETA: 0s - loss: 0.5485 - accuracy: 0.7328\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "684/804 [========================>.....] - ETA: 0s - loss: 0.5487 - accuracy: 0.7327\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "704/804 [=========================>....] - ETA: 0s - loss: 0.5491 - accuracy: 0.7322\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "724/804 [==========================>...] - ETA: 0s - loss: 0.5487 - accuracy: 0.7326\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "744/804 [==========================>...] - ETA: 0s - loss: 0.5477 - accuracy: 0.7330\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "764/804 [===========================>..] - ETA: 0s - loss: 0.5476 - accuracy: 0.7331\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "784/804 [============================>.] - ETA: 0s - loss: 0.5474 - accuracy: 0.7333\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "799/804 [============================>.] - ETA: 0s - loss: 0.5470 - accuracy: 0.7338\n",
      "Epoch 5: saving model to checkpoints_2\\weights.05.hdf5\n",
      "804/804 [==============================] - 2s 3ms/step - loss: 0.5470 - accuracy: 0.7337\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "fit_model = nn.fit(X_train_scaled, y_train, epochs=5, callbacks=[cp_callback])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - loss: 0.5598 - accuracy: 0.7240 - 247ms/epoch - 922us/step\n",
      "Loss: 0.559778094291687, Accuracy: 0.7239649891853333\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model using the test data\n",
    "model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code achieved the near 73% accuracy in 5 epochs for proof of concept. Next will test with the keras-tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(hp):\n",
    "    nn_model = tf.keras.models.Sequential()\n",
    "\n",
    "    # Allow kerastuner to decide which activation function to use in hidden layers\n",
    "    activation = hp.Choice('activation', ['relu', 'tanh', 'exponential', 'softmax'])\n",
    "\n",
    "    # Allow kerastuner to decide number of neurons in first layer\n",
    "    nn_model.add(tf.keras.layers.Dense(units=hp.Int('first_units',\n",
    "                                                    min_value=1,\n",
    "                                                    max_value=100,\n",
    "                                                    step=5),\n",
    "                                       activation=activation,\n",
    "                                       input_dim=len(X_train_scaled[0])))\n",
    "\n",
    "    # Allow kerastuner to decide number of hidden layers and neurons in hidden layers\n",
    "    for i in range(hp.Int('num_layers', 1, 5)):\n",
    "      nn_model.add(tf.keras.layers.Dense(units=hp.Int('units_' + str(i),\n",
    "                                                      min_value=1,\n",
    "                                                      max_value=100,\n",
    "                                                      step=5),\n",
    "                                         activation=activation))\n",
    "\n",
    "    nn_model.add(tf.keras.layers.Dense(units=1, activation=\"sigmoid\"))\n",
    "\n",
    "    # Compile the model\n",
    "    nn_model.compile(loss=\"binary_crossentropy\",\n",
    "                     optimizer='adam', metrics=[\"accuracy\"])\n",
    "\n",
    "    return nn_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "tuner = kt.Hyperband(\n",
    "    create_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_epochs=5,\n",
    "    hyperband_iterations=2,\n",
    "    overwrite=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 16 Complete [00h 00m 04s]\n",
      "val_accuracy: 0.726064145565033\n",
      "\n",
      "Best val_accuracy So Far: 0.7266472578048706\n",
      "Total elapsed time: 00h 01m 01s\n",
      "\n",
      "Search: Running Trial #17\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "softmax           |relu              |activation\n",
      "26                |86                |first_units\n",
      "2                 |2                 |num_layers\n",
      "11                |56                |units_0\n",
      "61                |61                |units_1\n",
      "31                |1                 |units_2\n",
      "91                |56                |units_3\n",
      "61                |96                |units_4\n",
      "5                 |5                 |tuner/epochs\n",
      "2                 |0                 |tuner/initial_epoch\n",
      "1                 |0                 |tuner/bracket\n",
      "1                 |0                 |tuner/round\n",
      "0012              |None              |tuner/trial_id\n",
      "\n",
      "Epoch 3/5\n",
      "207/804 [======>.......................] - ETA: 0s - loss: 0.6920 - accuracy: 0.5290"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_25456\\104789356.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Run the tuner search for the best hyperparameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m tuner.search(X_train_scaled, y_train, epochs=5,\n\u001b[1;32m----> 3\u001b[1;33m              validation_data=(X_test_scaled, y_test))\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\justi\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m             \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m             \u001b[1;31m# `results` is None indicates user updated oracle in `run_trial()`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresults\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\justi\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras_tuner\\tuners\\hyperband.py\u001b[0m in \u001b[0;36mrun_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    382\u001b[0m             \u001b[0mfit_kwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"epochs\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"tuner/epochs\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m             \u001b[0mfit_kwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"initial_epoch\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"tuner/initial_epoch\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHyperband\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_build_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\justi\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    293\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[0mcopied_kwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"callbacks\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m             \u001b[0mobj_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcopied_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m             \u001b[0mhistories\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\justi\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mhp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_try_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m         tuner_utils.validate_trial_results(\n\u001b[0;32m    224\u001b[0m             \u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"HyperModel.fit()\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\justi\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras_tuner\\engine\\hypermodel.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m             \u001b[0mIf\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mit\u001b[0m \u001b[0mshould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \"\"\"\n\u001b[1;32m--> 140\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\justi\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\justi\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1553\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_load_initial_step_from_ckpt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1554\u001b[0m                     )\n\u001b[1;32m-> 1555\u001b[1;33m                     \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1556\u001b[0m                         with tf.profiler.experimental.Trace(\n\u001b[0;32m   1557\u001b[0m                             \u001b[1;34m\"train\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\justi\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36msteps\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1372\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1373\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1374\u001b[1;33m             \u001b[0moriginal_spe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1375\u001b[0m             can_run_full_execution = (\n\u001b[0;32m   1376\u001b[0m                 \u001b[0moriginal_spe\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\justi\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    635\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 637\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    638\u001b[0m     raise NotImplementedError(\n\u001b[0;32m    639\u001b[0m         \"numpy() is only available when eager execution is enabled.\")\n",
      "\u001b[1;32mc:\\Users\\justi\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36mread_value\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    723\u001b[0m     \"\"\"\n\u001b[0;32m    724\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Read\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 725\u001b[1;33m       \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_variable_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    726\u001b[0m     \u001b[1;31m# Return an identity so it can get placed on whatever device the context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m     \u001b[1;31m# specifies instead of the device where the variable is.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\justi\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36m_read_variable_op\u001b[1;34m(self, no_copy)\u001b[0m\n\u001b[0;32m    702\u001b[0m           \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_and_set_handle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mno_copy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 704\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_and_set_handle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mno_copy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    705\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\justi\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36mread_and_set_handle\u001b[1;34m(no_copy)\u001b[0m\n\u001b[0;32m    693\u001b[0m         \u001b[0mgen_resource_variable_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisable_copy_on_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    694\u001b[0m       result = gen_resource_variable_ops.read_variable_op(\n\u001b[1;32m--> 695\u001b[1;33m           self.handle, self._dtype)\n\u001b[0m\u001b[0;32m    696\u001b[0m       \u001b[0m_maybe_set_handle_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    697\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\justi\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py\u001b[0m in \u001b[0;36mread_variable_op\u001b[1;34m(resource, dtype, name)\u001b[0m\n\u001b[0;32m    523\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m--> 525\u001b[1;33m         _ctx, \"ReadVariableOp\", name, resource, \"dtype\", dtype)\n\u001b[0m\u001b[0;32m    526\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run the tuner search for the best hyperparameters\n",
    "tuner.search(X_train_scaled, y_train, epochs=5,\n",
    "             validation_data=(X_test_scaled, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'first_units': 56, 'num_layers': 3, 'units_0': 56, 'units_1': 36, 'units_2': 26, 'tuner/epochs': 5, 'tuner/initial_epoch': 2, 'tuner/bracket': 1, 'tuner/round': 1, 'tuner/trial_id': '0002'}\n",
      "{'activation': 'relu', 'first_units': 36, 'num_layers': 2, 'units_0': 51, 'units_1': 41, 'units_2': 66, 'tuner/epochs': 5, 'tuner/initial_epoch': 0, 'tuner/bracket': 0, 'tuner/round': 0}\n",
      "{'activation': 'softmax', 'first_units': 36, 'num_layers': 3, 'units_0': 6, 'units_1': 21, 'units_2': 46, 'tuner/epochs': 5, 'tuner/initial_epoch': 0, 'tuner/bracket': 0, 'tuner/round': 0}\n"
     ]
    }
   ],
   "source": [
    "top_hyper=tuner.get_best_hyperparameters(3)\n",
    "for param in top_hyper:\n",
    "    print(param.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - loss: 0.5564 - accuracy: 0.7278 - 332ms/epoch - 1ms/step\n",
      "Loss: 0.5564, Accuracy: 0.7278\n",
      "268/268 - 0s - loss: 0.5591 - accuracy: 0.7264 - 313ms/epoch - 1ms/step\n",
      "Loss: 0.5591, Accuracy: 0.7264\n",
      "268/268 - 0s - loss: 0.5805 - accuracy: 0.7262 - 363ms/epoch - 1ms/step\n",
      "Loss: 0.5805, Accuracy: 0.7262\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the top 3 against the test dataset\n",
    "top_model = tuner.get_best_models(3)\n",
    "for model in top_model:\n",
    "    loss, accuracy = model.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "    print(f'Loss: {loss:.4f}, Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, none of the tuned models have exceeded 73%, so further data cleaning will be necessary to optimize the model. \n",
    "The different parameters are:\n",
    "Application Type\n",
    "Affiliation\n",
    "Classification\n",
    "Use Case\n",
    "Organization\n",
    "Status\n",
    "Income Amount\n",
    "Special Consideration\n",
    "Ask Amount\n",
    "\n",
    "Instead of doing a top down approach, and continuing to remove variables from the existing group, I'm going to try a bottom up approach and add back variables from a base set of the most superficial parameters to the more technical. \n",
    "\n",
    "Affiliation, Organization, and Use Case could be a very easy way to filter out applicants if the predictive ability is high.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>AFFILIATION_CompanySponsored</th>\n",
       "      <th>AFFILIATION_Family/Parent</th>\n",
       "      <th>AFFILIATION_Independent</th>\n",
       "      <th>AFFILIATION_National</th>\n",
       "      <th>AFFILIATION_Other</th>\n",
       "      <th>AFFILIATION_Regional</th>\n",
       "      <th>USE_CASE_CommunityServ</th>\n",
       "      <th>USE_CASE_Heathcare</th>\n",
       "      <th>USE_CASE_Other</th>\n",
       "      <th>USE_CASE_Preservation</th>\n",
       "      <th>USE_CASE_ProductDev</th>\n",
       "      <th>ORGANIZATION_Association</th>\n",
       "      <th>ORGANIZATION_Co-operative</th>\n",
       "      <th>ORGANIZATION_Corporation</th>\n",
       "      <th>ORGANIZATION_Trust</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   IS_SUCCESSFUL  AFFILIATION_CompanySponsored  AFFILIATION_Family/Parent  \\\n",
       "0              1                           0.0                        0.0   \n",
       "1              1                           0.0                        0.0   \n",
       "2              0                           1.0                        0.0   \n",
       "3              1                           1.0                        0.0   \n",
       "4              1                           0.0                        0.0   \n",
       "\n",
       "   AFFILIATION_Independent  AFFILIATION_National  AFFILIATION_Other  \\\n",
       "0                      1.0                   0.0                0.0   \n",
       "1                      1.0                   0.0                0.0   \n",
       "2                      0.0                   0.0                0.0   \n",
       "3                      0.0                   0.0                0.0   \n",
       "4                      1.0                   0.0                0.0   \n",
       "\n",
       "   AFFILIATION_Regional  USE_CASE_CommunityServ  USE_CASE_Heathcare  \\\n",
       "0                   0.0                     0.0                 0.0   \n",
       "1                   0.0                     0.0                 0.0   \n",
       "2                   0.0                     0.0                 0.0   \n",
       "3                   0.0                     0.0                 0.0   \n",
       "4                   0.0                     0.0                 1.0   \n",
       "\n",
       "   USE_CASE_Other  USE_CASE_Preservation  USE_CASE_ProductDev  \\\n",
       "0             0.0                    0.0                  1.0   \n",
       "1             0.0                    1.0                  0.0   \n",
       "2             0.0                    0.0                  1.0   \n",
       "3             0.0                    1.0                  0.0   \n",
       "4             0.0                    0.0                  0.0   \n",
       "\n",
       "   ORGANIZATION_Association  ORGANIZATION_Co-operative  \\\n",
       "0                       1.0                        0.0   \n",
       "1                       0.0                        1.0   \n",
       "2                       1.0                        0.0   \n",
       "3                       0.0                        0.0   \n",
       "4                       0.0                        0.0   \n",
       "\n",
       "   ORGANIZATION_Corporation  ORGANIZATION_Trust  \n",
       "0                       0.0                 0.0  \n",
       "1                       0.0                 0.0  \n",
       "2                       0.0                 0.0  \n",
       "3                       0.0                 1.0  \n",
       "4                       0.0                 1.0  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer_df = application_df[[\n",
    "    'IS_SUCCESSFUL',\n",
    "    'AFFILIATION_CompanySponsored', \n",
    "    'AFFILIATION_Family/Parent', \n",
    "    'AFFILIATION_Independent', \n",
    "    'AFFILIATION_National', \n",
    "    'AFFILIATION_Other', \n",
    "    'AFFILIATION_Regional',\n",
    "    'USE_CASE_CommunityServ',\n",
    "    'USE_CASE_Heathcare',\n",
    "    'USE_CASE_Other',\n",
    "    'USE_CASE_Preservation',\n",
    "    'USE_CASE_ProductDev',\n",
    "    'ORGANIZATION_Association',\n",
    "    'ORGANIZATION_Co-operative',\n",
    "    'ORGANIZATION_Corporation',\n",
    "    'ORGANIZATION_Trust']]\n",
    "optimizer_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate and scale parameters in the df\n",
    "X_train_scaled, X_test_scaled, y_train, y_test = df_trainer(optimizer_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 Complete [00h 00m 06s]\n",
      "val_accuracy: 0.6928279995918274\n",
      "\n",
      "Best val_accuracy So Far: 0.6928279995918274\n",
      "Total elapsed time: 00h 01m 22s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "# Tune with the same parameters as the previous model\n",
    "tuner = kt.Hyperband(\n",
    "    create_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_epochs=5,\n",
    "    hyperband_iterations=2,\n",
    "    overwrite=True)\n",
    "tuner.search(X_train_scaled, y_train, epochs=10, validation_data=(X_test_scaled, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - loss: 0.6135 - accuracy: 0.6928 - 323ms/epoch - 1ms/step\n",
      "Loss: 0.6135, Accuracy: 0.6928\n",
      "268/268 - 0s - loss: 0.6111 - accuracy: 0.6926 - 335ms/epoch - 1ms/step\n",
      "Loss: 0.6111, Accuracy: 0.6926\n",
      "268/268 - 0s - loss: 0.6484 - accuracy: 0.6924 - 343ms/epoch - 1ms/step\n",
      "Loss: 0.6484, Accuracy: 0.6924\n"
     ]
    }
   ],
   "source": [
    "top_model = tuner.get_best_models(3)\n",
    "for model in top_model:\n",
    "    loss, accuracy = model.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "    print(f'Loss: {loss:.4f}, Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\justi\\anaconda3\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\frame.py:3641: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    }
   ],
   "source": [
    "# These parameters alone had a reduced accuracy of 69.2%.  Adding income to the next set. \n",
    "additional_columns = [\n",
    "    'INCOME_AMT_0',\n",
    "    'INCOME_AMT_1-9999',\n",
    "    'INCOME_AMT_10000-24999',\n",
    "    'INCOME_AMT_100000-499999',\n",
    "    'INCOME_AMT_10M-50M',\n",
    "    'INCOME_AMT_1M-5M',\n",
    "    'INCOME_AMT_25000-99999',\n",
    "    'INCOME_AMT_50M+',\n",
    "    'INCOME_AMT_5M-10M']\n",
    " \n",
    "optimizer_df[additional_columns] = application_df[additional_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>AFFILIATION_CompanySponsored</th>\n",
       "      <th>AFFILIATION_Family/Parent</th>\n",
       "      <th>AFFILIATION_Independent</th>\n",
       "      <th>AFFILIATION_National</th>\n",
       "      <th>AFFILIATION_Other</th>\n",
       "      <th>AFFILIATION_Regional</th>\n",
       "      <th>USE_CASE_CommunityServ</th>\n",
       "      <th>USE_CASE_Heathcare</th>\n",
       "      <th>USE_CASE_Other</th>\n",
       "      <th>...</th>\n",
       "      <th>ORGANIZATION_Trust</th>\n",
       "      <th>INCOME_AMT_0</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   IS_SUCCESSFUL  AFFILIATION_CompanySponsored  AFFILIATION_Family/Parent  \\\n",
       "0              1                           0.0                        0.0   \n",
       "1              1                           0.0                        0.0   \n",
       "2              0                           1.0                        0.0   \n",
       "3              1                           1.0                        0.0   \n",
       "4              1                           0.0                        0.0   \n",
       "\n",
       "   AFFILIATION_Independent  AFFILIATION_National  AFFILIATION_Other  \\\n",
       "0                      1.0                   0.0                0.0   \n",
       "1                      1.0                   0.0                0.0   \n",
       "2                      0.0                   0.0                0.0   \n",
       "3                      0.0                   0.0                0.0   \n",
       "4                      1.0                   0.0                0.0   \n",
       "\n",
       "   AFFILIATION_Regional  USE_CASE_CommunityServ  USE_CASE_Heathcare  \\\n",
       "0                   0.0                     0.0                 0.0   \n",
       "1                   0.0                     0.0                 0.0   \n",
       "2                   0.0                     0.0                 0.0   \n",
       "3                   0.0                     0.0                 0.0   \n",
       "4                   0.0                     0.0                 1.0   \n",
       "\n",
       "   USE_CASE_Other  ...  ORGANIZATION_Trust  INCOME_AMT_0  INCOME_AMT_1-9999  \\\n",
       "0             0.0  ...                 0.0           1.0                0.0   \n",
       "1             0.0  ...                 0.0           0.0                1.0   \n",
       "2             0.0  ...                 0.0           1.0                0.0   \n",
       "3             0.0  ...                 1.0           0.0                0.0   \n",
       "4             0.0  ...                 1.0           0.0                0.0   \n",
       "\n",
       "   INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  INCOME_AMT_10M-50M  \\\n",
       "0                     0.0                       0.0                 0.0   \n",
       "1                     0.0                       0.0                 0.0   \n",
       "2                     0.0                       0.0                 0.0   \n",
       "3                     1.0                       0.0                 0.0   \n",
       "4                     0.0                       1.0                 0.0   \n",
       "\n",
       "   INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  INCOME_AMT_50M+  \\\n",
       "0               0.0                     0.0              0.0   \n",
       "1               0.0                     0.0              0.0   \n",
       "2               0.0                     0.0              0.0   \n",
       "3               0.0                     0.0              0.0   \n",
       "4               0.0                     0.0              0.0   \n",
       "\n",
       "   INCOME_AMT_5M-10M  \n",
       "0                0.0  \n",
       "1                0.0  \n",
       "2                0.0  \n",
       "3                0.0  \n",
       "4                0.0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 Complete [00h 00m 07s]\n",
      "val_accuracy: 0.6956267952919006\n",
      "\n",
      "Best val_accuracy So Far: 0.697842538356781\n",
      "Total elapsed time: 00h 01m 23s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "# Run tuner again with the additional income variables\n",
    "# Separate and scale parameters in the df\n",
    "X_train_scaled, X_test_scaled, y_train, y_test = df_trainer(optimizer_df)\n",
    "\n",
    "tuner = kt.Hyperband(\n",
    "    create_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_epochs=5,\n",
    "    hyperband_iterations=2,\n",
    "    overwrite=True)\n",
    "\n",
    "tuner.search(X_train_scaled, y_train, epochs=5, validation_data=(X_test_scaled, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - loss: 0.6100 - accuracy: 0.6978 - 313ms/epoch - 1ms/step\n",
      "Loss: 0.6100, Accuracy: 0.6978\n",
      "268/268 - 0s - loss: 0.6102 - accuracy: 0.6977 - 331ms/epoch - 1ms/step\n",
      "Loss: 0.6102, Accuracy: 0.6977\n",
      "268/268 - 0s - loss: 0.6077 - accuracy: 0.6975 - 326ms/epoch - 1ms/step\n",
      "Loss: 0.6077, Accuracy: 0.6975\n"
     ]
    }
   ],
   "source": [
    "top_model = tuner.get_best_models(3)\n",
    "for model in top_model:\n",
    "    loss, accuracy = model.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "    print(f'Loss: {loss:.4f}, Accuracy: {accuracy:.4f}')\n",
    "\n",
    "\n",
    "# This increase the accuracy to 69.8%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\justi\\anaconda3\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\frame.py:3641: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>AFFILIATION_CompanySponsored</th>\n",
       "      <th>AFFILIATION_Family/Parent</th>\n",
       "      <th>AFFILIATION_Independent</th>\n",
       "      <th>AFFILIATION_National</th>\n",
       "      <th>AFFILIATION_Other</th>\n",
       "      <th>AFFILIATION_Regional</th>\n",
       "      <th>USE_CASE_CommunityServ</th>\n",
       "      <th>USE_CASE_Heathcare</th>\n",
       "      <th>USE_CASE_Other</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>APPLICATION_TYPE_Other</th>\n",
       "      <th>APPLICATION_TYPE_T10</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>APPLICATION_TYPE_T4</th>\n",
       "      <th>APPLICATION_TYPE_T5</th>\n",
       "      <th>APPLICATION_TYPE_T6</th>\n",
       "      <th>APPLICATION_TYPE_T7</th>\n",
       "      <th>APPLICATION_TYPE_T8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   IS_SUCCESSFUL  AFFILIATION_CompanySponsored  AFFILIATION_Family/Parent  \\\n",
       "0              1                           0.0                        0.0   \n",
       "1              1                           0.0                        0.0   \n",
       "2              0                           1.0                        0.0   \n",
       "3              1                           1.0                        0.0   \n",
       "4              1                           0.0                        0.0   \n",
       "\n",
       "   AFFILIATION_Independent  AFFILIATION_National  AFFILIATION_Other  \\\n",
       "0                      1.0                   0.0                0.0   \n",
       "1                      1.0                   0.0                0.0   \n",
       "2                      0.0                   0.0                0.0   \n",
       "3                      0.0                   0.0                0.0   \n",
       "4                      1.0                   0.0                0.0   \n",
       "\n",
       "   AFFILIATION_Regional  USE_CASE_CommunityServ  USE_CASE_Heathcare  \\\n",
       "0                   0.0                     0.0                 0.0   \n",
       "1                   0.0                     0.0                 0.0   \n",
       "2                   0.0                     0.0                 0.0   \n",
       "3                   0.0                     0.0                 0.0   \n",
       "4                   0.0                     0.0                 1.0   \n",
       "\n",
       "   USE_CASE_Other  ...  INCOME_AMT_5M-10M  APPLICATION_TYPE_Other  \\\n",
       "0             0.0  ...                0.0                     0.0   \n",
       "1             0.0  ...                0.0                     0.0   \n",
       "2             0.0  ...                0.0                     0.0   \n",
       "3             0.0  ...                0.0                     0.0   \n",
       "4             0.0  ...                0.0                     0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T10  APPLICATION_TYPE_T19  APPLICATION_TYPE_T3  \\\n",
       "0                   1.0                   0.0                  0.0   \n",
       "1                   0.0                   0.0                  1.0   \n",
       "2                   0.0                   0.0                  0.0   \n",
       "3                   0.0                   0.0                  1.0   \n",
       "4                   0.0                   0.0                  1.0   \n",
       "\n",
       "   APPLICATION_TYPE_T4  APPLICATION_TYPE_T5  APPLICATION_TYPE_T6  \\\n",
       "0                  0.0                  0.0                  0.0   \n",
       "1                  0.0                  0.0                  0.0   \n",
       "2                  0.0                  1.0                  0.0   \n",
       "3                  0.0                  0.0                  0.0   \n",
       "4                  0.0                  0.0                  0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T7  APPLICATION_TYPE_T8  \n",
       "0                  0.0                  0.0  \n",
       "1                  0.0                  0.0  \n",
       "2                  0.0                  0.0  \n",
       "3                  0.0                  0.0  \n",
       "4                  0.0                  0.0  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Add in the application type\n",
    "additional_columns = [\n",
    "    'APPLICATION_TYPE_Other',\n",
    "    'APPLICATION_TYPE_T10',\n",
    "    'APPLICATION_TYPE_T19',\n",
    "    'APPLICATION_TYPE_T3',\n",
    "    'APPLICATION_TYPE_T4',\n",
    "    'APPLICATION_TYPE_T5',\n",
    "    'APPLICATION_TYPE_T6',\n",
    "    'APPLICATION_TYPE_T7',\n",
    "    'APPLICATION_TYPE_T8']\n",
    "\n",
    "optimizer_df[additional_columns] = application_df[additional_columns]\n",
    "optimizer_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 Complete [00h 00m 06s]\n",
      "val_accuracy: 0.7213994264602661\n",
      "\n",
      "Best val_accuracy So Far: 0.723498523235321\n",
      "Total elapsed time: 00h 01m 25s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "# Run tuner again with the application type\n",
    "# Separate and scale parameters in the df\n",
    "X_train_scaled, X_test_scaled, y_train, y_test = df_trainer(optimizer_df)\n",
    "\n",
    "tuner = kt.Hyperband(\n",
    "    create_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_epochs=5,\n",
    "    hyperband_iterations=2,\n",
    "    overwrite=True)\n",
    "\n",
    "tuner.search(X_train_scaled, y_train, epochs=5,\n",
    "             validation_data=(X_test_scaled, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - loss: 0.5770 - accuracy: 0.7235 - 348ms/epoch - 1ms/step\n",
      "Loss: 0.5770, Accuracy: 0.7235\n",
      "268/268 - 0s - loss: 0.5800 - accuracy: 0.7226 - 333ms/epoch - 1ms/step\n",
      "Loss: 0.5800, Accuracy: 0.7226\n",
      "268/268 - 0s - loss: 0.5823 - accuracy: 0.7224 - 320ms/epoch - 1ms/step\n",
      "Loss: 0.5823, Accuracy: 0.7224\n"
     ]
    }
   ],
   "source": [
    "top_model = tuner.get_best_models(3)\n",
    "for model in top_model:\n",
    "    loss, accuracy = model.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "    print(f'Loss: {loss:.4f}, Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Adding the application type brought the model back up to 72.3%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\justi\\anaconda3\\envs\\mlenv\\lib\\site-packages\\pandas\\core\\frame.py:3641: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self[k1] = value[k2]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>AFFILIATION_CompanySponsored</th>\n",
       "      <th>AFFILIATION_Family/Parent</th>\n",
       "      <th>AFFILIATION_Independent</th>\n",
       "      <th>AFFILIATION_National</th>\n",
       "      <th>AFFILIATION_Other</th>\n",
       "      <th>AFFILIATION_Regional</th>\n",
       "      <th>USE_CASE_CommunityServ</th>\n",
       "      <th>USE_CASE_Heathcare</th>\n",
       "      <th>USE_CASE_Other</th>\n",
       "      <th>...</th>\n",
       "      <th>APPLICATION_TYPE_T5</th>\n",
       "      <th>APPLICATION_TYPE_T6</th>\n",
       "      <th>APPLICATION_TYPE_T7</th>\n",
       "      <th>APPLICATION_TYPE_T8</th>\n",
       "      <th>CLASSIFICATION_C1000</th>\n",
       "      <th>CLASSIFICATION_C1200</th>\n",
       "      <th>CLASSIFICATION_C2000</th>\n",
       "      <th>CLASSIFICATION_C2100</th>\n",
       "      <th>CLASSIFICATION_C3000</th>\n",
       "      <th>CLASSIFICATION_Other</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   IS_SUCCESSFUL  AFFILIATION_CompanySponsored  AFFILIATION_Family/Parent  \\\n",
       "0              1                           0.0                        0.0   \n",
       "1              1                           0.0                        0.0   \n",
       "2              0                           1.0                        0.0   \n",
       "3              1                           1.0                        0.0   \n",
       "4              1                           0.0                        0.0   \n",
       "\n",
       "   AFFILIATION_Independent  AFFILIATION_National  AFFILIATION_Other  \\\n",
       "0                      1.0                   0.0                0.0   \n",
       "1                      1.0                   0.0                0.0   \n",
       "2                      0.0                   0.0                0.0   \n",
       "3                      0.0                   0.0                0.0   \n",
       "4                      1.0                   0.0                0.0   \n",
       "\n",
       "   AFFILIATION_Regional  USE_CASE_CommunityServ  USE_CASE_Heathcare  \\\n",
       "0                   0.0                     0.0                 0.0   \n",
       "1                   0.0                     0.0                 0.0   \n",
       "2                   0.0                     0.0                 0.0   \n",
       "3                   0.0                     0.0                 0.0   \n",
       "4                   0.0                     0.0                 1.0   \n",
       "\n",
       "   USE_CASE_Other  ...  APPLICATION_TYPE_T5  APPLICATION_TYPE_T6  \\\n",
       "0             0.0  ...                  0.0                  0.0   \n",
       "1             0.0  ...                  0.0                  0.0   \n",
       "2             0.0  ...                  1.0                  0.0   \n",
       "3             0.0  ...                  0.0                  0.0   \n",
       "4             0.0  ...                  0.0                  0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T7  APPLICATION_TYPE_T8  CLASSIFICATION_C1000  \\\n",
       "0                  0.0                  0.0                   1.0   \n",
       "1                  0.0                  0.0                   0.0   \n",
       "2                  0.0                  0.0                   0.0   \n",
       "3                  0.0                  0.0                   0.0   \n",
       "4                  0.0                  0.0                   1.0   \n",
       "\n",
       "   CLASSIFICATION_C1200  CLASSIFICATION_C2000  CLASSIFICATION_C2100  \\\n",
       "0                   0.0                   0.0                   0.0   \n",
       "1                   0.0                   1.0                   0.0   \n",
       "2                   0.0                   0.0                   0.0   \n",
       "3                   0.0                   1.0                   0.0   \n",
       "4                   0.0                   0.0                   0.0   \n",
       "\n",
       "   CLASSIFICATION_C3000  CLASSIFICATION_Other  \n",
       "0                   0.0                   0.0  \n",
       "1                   0.0                   0.0  \n",
       "2                   1.0                   0.0  \n",
       "3                   0.0                   0.0  \n",
       "4                   0.0                   0.0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "additional_columns = [\n",
    "    'CLASSIFICATION_C1000'    ,\n",
    "    'CLASSIFICATION_C1200'   ,\n",
    "    'CLASSIFICATION_C2000'  ,\n",
    "    'CLASSIFICATION_C2100' ,\n",
    "    'CLASSIFICATION_C3000',\n",
    "    'CLASSIFICATION_Other']\n",
    "\n",
    "optimizer_df[additional_columns] = application_df[additional_columns]\n",
    "optimizer_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 Complete [00h 00m 06s]\n",
      "val_accuracy: 0.7245481014251709\n",
      "\n",
      "Best val_accuracy So Far: 0.7268804907798767\n",
      "Total elapsed time: 00h 01m 22s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "# Run tuner again with the classification\n",
    "# Separate and scale parameters in the df\n",
    "X_train_scaled, X_test_scaled, y_train, y_test = df_trainer(optimizer_df)\n",
    "\n",
    "tuner = kt.Hyperband(\n",
    "    create_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_epochs=5,\n",
    "    hyperband_iterations=2,\n",
    "    overwrite=True)\n",
    "\n",
    "tuner.search(X_train_scaled, y_train, epochs=5,\n",
    "             validation_data=(X_test_scaled, y_test))\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - loss: 0.5638 - accuracy: 0.7269 - 341ms/epoch - 1ms/step\n",
      "Loss: 0.5638, Accuracy: 0.7269\n",
      "268/268 - 0s - loss: 0.5597 - accuracy: 0.7262 - 362ms/epoch - 1ms/step\n",
      "Loss: 0.5597, Accuracy: 0.7262\n",
      "268/268 - 0s - loss: 0.5612 - accuracy: 0.7262 - 310ms/epoch - 1ms/step\n",
      "Loss: 0.5612, Accuracy: 0.7262\n"
     ]
    }
   ],
   "source": [
    "top_model = tuner.get_best_models(3)\n",
    "for model in top_model:\n",
    "    loss, accuracy = model.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "    print(f'Loss: {loss:.4f}, Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# the classification marginally increased the accuracy to 72.7%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_df[\"ASK_BIN\"] = application_df[\"ASK_BIN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 Complete [00h 00m 06s]\n",
      "val_accuracy: 0.7266472578048706\n",
      "\n",
      "Best val_accuracy So Far: 0.727580189704895\n",
      "Total elapsed time: 00h 01m 23s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "# Run tuner again with the asking amount binned into 5 categories, at this point, the only category missing is the special considerations\n",
    "# Separate and scale parameters in the df\n",
    "X_train_scaled, X_test_scaled, y_train, y_test = df_trainer(optimizer_df)\n",
    "\n",
    "tuner = kt.Hyperband(\n",
    "    create_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_epochs=5,\n",
    "    hyperband_iterations=2,\n",
    "    overwrite=True)\n",
    "\n",
    "tuner.search(X_train_scaled, y_train, epochs=5,\n",
    "             validation_data=(X_test_scaled, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - loss: 0.5813 - accuracy: 0.7276 - 315ms/epoch - 1ms/step\n",
      "Loss: 0.5813, Accuracy: 0.7276\n",
      "268/268 - 0s - loss: 0.5558 - accuracy: 0.7269 - 381ms/epoch - 1ms/step\n",
      "Loss: 0.5558, Accuracy: 0.7269\n",
      "268/268 - 0s - loss: 0.5815 - accuracy: 0.7268 - 307ms/epoch - 1ms/step\n",
      "Loss: 0.5815, Accuracy: 0.7268\n"
     ]
    }
   ],
   "source": [
    "top_model = tuner.get_best_models(3)\n",
    "for model in top_model:\n",
    "    loss, accuracy = model.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "    print(f'Loss: {loss:.4f}, Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# the asking amounts didn't change the accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Since the bottom up starting with the superficial parameters, we'll now remove those parameters with a top-down removal from the original df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['AFFILIATION_CompanySponsored',\n",
    "           'AFFILIATION_Family/Parent',\n",
    "           'AFFILIATION_Independent',\n",
    "           'AFFILIATION_National',\n",
    "           'AFFILIATION_Other',\n",
    "           'AFFILIATION_Regional']\n",
    "\n",
    "optimizer_df = application_df.drop(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 Complete [00h 00m 07s]\n",
      "val_accuracy: 0.6474635601043701\n",
      "\n",
      "Best val_accuracy So Far: 0.6492128372192383\n",
      "Total elapsed time: 00h 01m 25s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "X_train_scaled, X_test_scaled, y_train, y_test = df_trainer(optimizer_df)\n",
    "\n",
    "tuner = kt.Hyperband(\n",
    "    create_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_epochs=5,\n",
    "    hyperband_iterations=2,\n",
    "    overwrite=True)\n",
    "\n",
    "tuner.search(X_train_scaled, y_train, epochs=5,\n",
    "             validation_data=(X_test_scaled, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - loss: 0.6173 - accuracy: 0.6492 - 334ms/epoch - 1ms/step\n",
      "Loss: 0.6173, Accuracy: 0.6492\n",
      "268/268 - 0s - loss: 0.6174 - accuracy: 0.6484 - 338ms/epoch - 1ms/step\n",
      "Loss: 0.6174, Accuracy: 0.6484\n",
      "268/268 - 0s - loss: 0.6185 - accuracy: 0.6484 - 336ms/epoch - 1ms/step\n",
      "Loss: 0.6185, Accuracy: 0.6484\n"
     ]
    }
   ],
   "source": [
    "top_model = tuner.get_best_models(3)\n",
    "for model in top_model:\n",
    "    loss, accuracy = model.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "    print(f'Loss: {loss:.4f}, Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Removing affiliation drastically reduced the accuracy \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trying by removing Use Case\n",
    "\n",
    "columns = ['USE_CASE_CommunityServ',\n",
    "           'USE_CASE_Heathcare',\n",
    "           'USE_CASE_Other',\n",
    "           'USE_CASE_Preservation',\n",
    "           'USE_CASE_ProductDev']\n",
    "\n",
    "optimizer_df = application_df.drop(columns=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 Complete [00h 00m 07s]\n",
      "val_accuracy: 0.726064145565033\n",
      "\n",
      "Best val_accuracy So Far: 0.7278134226799011\n",
      "Total elapsed time: 00h 01m 27s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "X_train_scaled, X_test_scaled, y_train, y_test = df_trainer(optimizer_df)\n",
    "\n",
    "tuner = kt.Hyperband(\n",
    "    create_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_epochs=5,\n",
    "    hyperband_iterations=2,\n",
    "    overwrite=True)\n",
    "\n",
    "tuner.search(X_train_scaled, y_train, epochs=5,\n",
    "             validation_data=(X_test_scaled, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - loss: 0.5763 - accuracy: 0.7278 - 322ms/epoch - 1ms/step\n",
      "Loss: 0.5763, Accuracy: 0.7278\n",
      "268/268 - 0s - loss: 0.5750 - accuracy: 0.7270 - 340ms/epoch - 1ms/step\n",
      "Loss: 0.5750, Accuracy: 0.7270\n",
      "268/268 - 0s - loss: 0.5613 - accuracy: 0.7268 - 314ms/epoch - 1ms/step\n",
      "Loss: 0.5613, Accuracy: 0.7268\n"
     ]
    }
   ],
   "source": [
    "top_model = tuner.get_best_models(3)\n",
    "for model in top_model:\n",
    "    loss, accuracy = model.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "    print(f'Loss: {loss:.4f}, Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Removing Use Case had no effect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATUS</th>\n",
       "      <th>IS_SUCCESSFUL</th>\n",
       "      <th>APPLICATION_TYPE_Other</th>\n",
       "      <th>APPLICATION_TYPE_T10</th>\n",
       "      <th>APPLICATION_TYPE_T19</th>\n",
       "      <th>APPLICATION_TYPE_T3</th>\n",
       "      <th>APPLICATION_TYPE_T4</th>\n",
       "      <th>APPLICATION_TYPE_T5</th>\n",
       "      <th>APPLICATION_TYPE_T6</th>\n",
       "      <th>APPLICATION_TYPE_T7</th>\n",
       "      <th>...</th>\n",
       "      <th>INCOME_AMT_1-9999</th>\n",
       "      <th>INCOME_AMT_10000-24999</th>\n",
       "      <th>INCOME_AMT_100000-499999</th>\n",
       "      <th>INCOME_AMT_10M-50M</th>\n",
       "      <th>INCOME_AMT_1M-5M</th>\n",
       "      <th>INCOME_AMT_25000-99999</th>\n",
       "      <th>INCOME_AMT_50M+</th>\n",
       "      <th>INCOME_AMT_5M-10M</th>\n",
       "      <th>SPECIAL_CONSIDERATIONS_Y</th>\n",
       "      <th>ASK_BIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   STATUS  IS_SUCCESSFUL  APPLICATION_TYPE_Other  APPLICATION_TYPE_T10  \\\n",
       "0       1              1                     0.0                   1.0   \n",
       "1       1              1                     0.0                   0.0   \n",
       "2       1              0                     0.0                   0.0   \n",
       "3       1              1                     0.0                   0.0   \n",
       "4       1              1                     0.0                   0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T19  APPLICATION_TYPE_T3  APPLICATION_TYPE_T4  \\\n",
       "0                   0.0                  0.0                  0.0   \n",
       "1                   0.0                  1.0                  0.0   \n",
       "2                   0.0                  0.0                  0.0   \n",
       "3                   0.0                  1.0                  0.0   \n",
       "4                   0.0                  1.0                  0.0   \n",
       "\n",
       "   APPLICATION_TYPE_T5  APPLICATION_TYPE_T6  APPLICATION_TYPE_T7  ...  \\\n",
       "0                  0.0                  0.0                  0.0  ...   \n",
       "1                  0.0                  0.0                  0.0  ...   \n",
       "2                  1.0                  0.0                  0.0  ...   \n",
       "3                  0.0                  0.0                  0.0  ...   \n",
       "4                  0.0                  0.0                  0.0  ...   \n",
       "\n",
       "   INCOME_AMT_1-9999  INCOME_AMT_10000-24999  INCOME_AMT_100000-499999  \\\n",
       "0                0.0                     0.0                       0.0   \n",
       "1                1.0                     0.0                       0.0   \n",
       "2                0.0                     0.0                       0.0   \n",
       "3                0.0                     1.0                       0.0   \n",
       "4                0.0                     0.0                       1.0   \n",
       "\n",
       "   INCOME_AMT_10M-50M  INCOME_AMT_1M-5M  INCOME_AMT_25000-99999  \\\n",
       "0                 0.0               0.0                     0.0   \n",
       "1                 0.0               0.0                     0.0   \n",
       "2                 0.0               0.0                     0.0   \n",
       "3                 0.0               0.0                     0.0   \n",
       "4                 0.0               0.0                     0.0   \n",
       "\n",
       "   INCOME_AMT_50M+  INCOME_AMT_5M-10M  SPECIAL_CONSIDERATIONS_Y  ASK_BIN  \n",
       "0              0.0                0.0                       0.0        1  \n",
       "1              0.0                0.0                       0.0        4  \n",
       "2              0.0                0.0                       0.0        1  \n",
       "3              0.0                0.0                       0.0        2  \n",
       "4              0.0                0.0                       0.0        4  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove organization in addition to the Use Case\n",
    "columns = [\n",
    "    'ORGANIZATION_Association',\n",
    "    'ORGANIZATION_Co-operative',\n",
    "    'ORGANIZATION_Corporation',\n",
    "    'ORGANIZATION_Trust']\n",
    "optimizer_df = optimizer_df.drop(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 Complete [00h 00m 07s]\n",
      "val_accuracy: 0.4676384925842285\n",
      "\n",
      "Best val_accuracy So Far: 0.72116619348526\n",
      "Total elapsed time: 00h 01m 27s\n",
      "INFO:tensorflow:Oracle triggered exit\n",
      "268/268 - 0s - loss: 0.5840 - accuracy: 0.7212 - 300ms/epoch - 1ms/step\n",
      "Loss: 0.5840, Accuracy: 0.7212\n",
      "268/268 - 0s - loss: 0.5864 - accuracy: 0.7209 - 305ms/epoch - 1ms/step\n",
      "Loss: 0.5864, Accuracy: 0.7209\n",
      "268/268 - 0s - loss: 0.5728 - accuracy: 0.7201 - 322ms/epoch - 1ms/step\n",
      "Loss: 0.5728, Accuracy: 0.7201\n"
     ]
    }
   ],
   "source": [
    "X_train_scaled, X_test_scaled, y_train, y_test = df_trainer(optimizer_df)\n",
    "\n",
    "tuner = kt.Hyperband(\n",
    "    create_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_epochs=5,\n",
    "    hyperband_iterations=2,\n",
    "    overwrite=True)\n",
    "\n",
    "tuner.search(X_train_scaled, y_train, epochs=5,\n",
    "             validation_data=(X_test_scaled, y_test))\n",
    "\n",
    "top_model = tuner.get_best_models(3)\n",
    "for model in top_model:\n",
    "    loss, accuracy = model.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "    print(f'Loss: {loss:.4f}, Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Removing the organization reduced the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['USE_CASE_CommunityServ',\n",
    "           'USE_CASE_Heathcare',\n",
    "           'USE_CASE_Other',\n",
    "           'USE_CASE_Preservation',\n",
    "           'USE_CASE_ProductDev', \n",
    "           'ASK_BIN']\n",
    "\n",
    "optimizer_df = application_df.drop(columns=columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 Complete [00h 00m 06s]\n",
      "val_accuracy: 0.7262973785400391\n",
      "\n",
      "Best val_accuracy So Far: 0.7267638444900513\n",
      "Total elapsed time: 00h 01m 26s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "X_train_scaled, X_test_scaled, y_train, y_test = df_trainer(optimizer_df)\n",
    "\n",
    "tuner = kt.Hyperband(\n",
    "    create_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_epochs=5,\n",
    "    hyperband_iterations=2,\n",
    "    overwrite=True)\n",
    "\n",
    "tuner.search(X_train_scaled, y_train, epochs=5,\n",
    "             validation_data=(X_test_scaled, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - loss: 0.5766 - accuracy: 0.7268 - 304ms/epoch - 1ms/step\n",
      "Loss: 0.5766, Accuracy: 0.7268\n",
      "268/268 - 0s - loss: 0.5624 - accuracy: 0.7266 - 337ms/epoch - 1ms/step\n",
      "Loss: 0.5624, Accuracy: 0.7266\n",
      "268/268 - 0s - loss: 0.5803 - accuracy: 0.7266 - 322ms/epoch - 1ms/step\n",
      "Loss: 0.5803, Accuracy: 0.7266\n"
     ]
    }
   ],
   "source": [
    "top_model = tuner.get_best_models(3)\n",
    "for model in top_model:\n",
    "    loss, accuracy = model.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "    print(f'Loss: {loss:.4f}, Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Accuracy is improved by removing the ask bins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 Complete [00h 00m 06s]\n",
      "val_accuracy: 0.7262973785400391\n",
      "\n",
      "Best val_accuracy So Far: 0.7266472578048706\n",
      "Total elapsed time: 00h 01m 25s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "columns = ['USE_CASE_CommunityServ',\n",
    "           'USE_CASE_Heathcare',\n",
    "           'USE_CASE_Other',\n",
    "           'USE_CASE_Preservation',\n",
    "           'USE_CASE_ProductDev',\n",
    "           'ASK_BIN', \n",
    "           'SPECIAL_CONSIDERATIONS_Y']\n",
    "\n",
    "optimizer_df = application_df.drop(columns=columns)\n",
    "X_train_scaled, X_test_scaled, y_train, y_test = df_trainer(optimizer_df)\n",
    "\n",
    "tuner = kt.Hyperband(\n",
    "    create_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_epochs=5,\n",
    "    hyperband_iterations=2,\n",
    "    overwrite=True)\n",
    "\n",
    "tuner.search(X_train_scaled, y_train, epochs=5,\n",
    "             validation_data=(X_test_scaled, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - loss: 0.5750 - accuracy: 0.7266 - 307ms/epoch - 1ms/step\n",
      "Loss: 0.5750, Accuracy: 0.7266\n",
      "268/268 - 0s - loss: 0.5782 - accuracy: 0.7265 - 338ms/epoch - 1ms/step\n",
      "Loss: 0.5782, Accuracy: 0.7265\n",
      "268/268 - 0s - loss: 0.5809 - accuracy: 0.7265 - 417ms/epoch - 2ms/step\n",
      "Loss: 0.5809, Accuracy: 0.7265\n"
     ]
    }
   ],
   "source": [
    "top_model = tuner.get_best_models(3)\n",
    "for model in top_model:\n",
    "    loss, accuracy = model.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "    print(f'Loss: {loss:.4f}, Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Accuracy is slightly reduced with removal of the special considerations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 Complete [00h 00m 07s]\n",
      "val_accuracy: 0.7261807322502136\n",
      "\n",
      "Best val_accuracy So Far: 0.7262973785400391\n",
      "Total elapsed time: 00h 01m 27s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "columns = ['USE_CASE_CommunityServ',\n",
    "           'USE_CASE_Heathcare',\n",
    "           'USE_CASE_Other',\n",
    "           'USE_CASE_Preservation',\n",
    "           'USE_CASE_ProductDev',\n",
    "           'ASK_BIN',\n",
    "           'STATUS']\n",
    "\n",
    "optimizer_df = application_df.drop(columns=columns)\n",
    "X_train_scaled, X_test_scaled, y_train, y_test = df_trainer(optimizer_df)\n",
    "\n",
    "tuner = kt.Hyperband(\n",
    "    create_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_epochs=5,\n",
    "    hyperband_iterations=2,\n",
    "    overwrite=True)\n",
    "\n",
    "tuner.search(X_train_scaled, y_train, epochs=5,\n",
    "             validation_data=(X_test_scaled, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - loss: 0.5766 - accuracy: 0.7263 - 309ms/epoch - 1ms/step\n",
      "Loss: 0.5766, Accuracy: 0.7263\n",
      "268/268 - 0s - loss: 0.5820 - accuracy: 0.7262 - 346ms/epoch - 1ms/step\n",
      "Loss: 0.5820, Accuracy: 0.7262\n",
      "268/268 - 0s - loss: 0.5685 - accuracy: 0.7259 - 303ms/epoch - 1ms/step\n",
      "Loss: 0.5685, Accuracy: 0.7259\n"
     ]
    }
   ],
   "source": [
    "top_model = tuner.get_best_models(3)\n",
    "for model in top_model:\n",
    "    loss, accuracy = model.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "    print(f'Loss: {loss:.4f}, Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Accuracy is slightly reduced with removal of status\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 Complete [00h 00m 06s]\n",
      "val_accuracy: 0.4676384925842285\n",
      "\n",
      "Best val_accuracy So Far: 0.7220991253852844\n",
      "Total elapsed time: 00h 01m 28s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "columns = ['USE_CASE_CommunityServ',\n",
    "           'USE_CASE_Heathcare',\n",
    "           'USE_CASE_Other',\n",
    "           'USE_CASE_Preservation',\n",
    "           'USE_CASE_ProductDev', \n",
    "           'ASK_BIN',\n",
    "           'INCOME_AMT_0',\n",
    "           'INCOME_AMT_1-9999',\n",
    "           'INCOME_AMT_10000-24999',\n",
    "           'INCOME_AMT_100000-499999',\n",
    "           'INCOME_AMT_10M-50M',\n",
    "           'INCOME_AMT_1M-5M',\n",
    "           'INCOME_AMT_25000-99999',\n",
    "           'INCOME_AMT_50M+',\n",
    "           'INCOME_AMT_5M-10M']\n",
    "\n",
    "optimizer_df = application_df.drop(columns=columns)\n",
    "X_train_scaled, X_test_scaled, y_train, y_test = df_trainer(optimizer_df)\n",
    "\n",
    "tuner = kt.Hyperband(\n",
    "    create_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_epochs=5,\n",
    "    hyperband_iterations=2,\n",
    "    overwrite=True)\n",
    "\n",
    "tuner.search(X_train_scaled, y_train, epochs=5,\n",
    "             validation_data=(X_test_scaled, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - loss: 0.5698 - accuracy: 0.7221 - 319ms/epoch - 1ms/step\n",
      "Loss: 0.5698, Accuracy: 0.7221\n",
      "268/268 - 0s - loss: 0.5688 - accuracy: 0.7219 - 324ms/epoch - 1ms/step\n",
      "Loss: 0.5688, Accuracy: 0.7219\n",
      "268/268 - 0s - loss: 0.5677 - accuracy: 0.7216 - 329ms/epoch - 1ms/step\n",
      "Loss: 0.5677, Accuracy: 0.7216\n"
     ]
    }
   ],
   "source": [
    "top_model = tuner.get_best_models(3)\n",
    "for model in top_model:\n",
    "    loss, accuracy = model.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "    print(f'Loss: {loss:.4f}, Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Accuracy is slightly reduced with removal of income - best so far has been removal of use-case and ask-bin\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 20 Complete [00h 00m 07s]\n",
      "val_accuracy: 0.726064145565033\n",
      "\n",
      "Best val_accuracy So Far: 0.727580189704895\n",
      "Total elapsed time: 00h 01m 31s\n",
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    }
   ],
   "source": [
    "# Increased the function to increase hidden layer possibilities to 100 and layers to 5\n",
    "columns = ['USE_CASE_CommunityServ',\n",
    "           'USE_CASE_Heathcare',\n",
    "           'USE_CASE_Other',\n",
    "           'USE_CASE_Preservation',\n",
    "           'USE_CASE_ProductDev',\n",
    "           'ASK_BIN']\n",
    "\n",
    "optimizer_df = application_df.drop(columns=columns)\n",
    "X_train_scaled, X_test_scaled, y_train, y_test = df_trainer(optimizer_df)\n",
    "\n",
    "tuner = kt.Hyperband(\n",
    "    create_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_epochs=5,\n",
    "    hyperband_iterations=2,\n",
    "    overwrite=True)\n",
    "\n",
    "tuner.search(X_train_scaled, y_train, epochs=5,\n",
    "             validation_data=(X_test_scaled, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - loss: 0.5635 - accuracy: 0.7276 - 324ms/epoch - 1ms/step\n",
      "Loss: 0.5635, Accuracy: 0.7276\n",
      "268/268 - 0s - loss: 0.5654 - accuracy: 0.7270 - 354ms/epoch - 1ms/step\n",
      "Loss: 0.5654, Accuracy: 0.7270\n",
      "268/268 - 0s - loss: 0.5662 - accuracy: 0.7263 - 332ms/epoch - 1ms/step\n",
      "Loss: 0.5662, Accuracy: 0.7263\n"
     ]
    }
   ],
   "source": [
    "top_model = tuner.get_best_models(3)\n",
    "for model in top_model:\n",
    "    loss, accuracy = model.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "    print(f'Loss: {loss:.4f}, Accuracy: {accuracy:.4f}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'tanh', 'first_units': 36, 'num_layers': 3, 'units_0': 21, 'units_1': 66, 'units_2': 91, 'tuner/epochs': 5, 'tuner/initial_epoch': 2, 'tuner/bracket': 1, 'tuner/round': 1, 'tuner/trial_id': '0003'}\n",
      "{'activation': 'relu', 'first_units': 41, 'num_layers': 5, 'units_0': 56, 'units_1': 76, 'units_2': 36, 'units_3': 21, 'units_4': 36, 'tuner/epochs': 5, 'tuner/initial_epoch': 0, 'tuner/bracket': 0, 'tuner/round': 0}\n",
      "{'activation': 'tanh', 'first_units': 36, 'num_layers': 3, 'units_0': 21, 'units_1': 66, 'units_2': 91, 'tuner/epochs': 2, 'tuner/initial_epoch': 0, 'tuner/bracket': 1, 'tuner/round': 0}\n"
     ]
    }
   ],
   "source": [
    "top_hyper = tuner.get_best_hyperparameters(3)\n",
    "for param in top_hyper:\n",
    "    print(param.values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Going to test by increasing to 200 epochs now that the parameters are optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 501 Complete [00h 02m 15s]\n",
      "val_accuracy: 0.7267638444900513\n",
      "\n",
      "Best val_accuracy So Far: 0.7280466556549072\n",
      "Total elapsed time: 02h 40m 05s\n",
      "\n",
      "Search: Running Trial #502\n",
      "\n",
      "Value             |Best Value So Far |Hyperparameter\n",
      "tanh              |relu              |activation\n",
      "81                |21                |first_units\n",
      "2                 |2                 |num_layers\n",
      "31                |71                |units_0\n",
      "66                |21                |units_1\n",
      "76                |11                |units_2\n",
      "51                |61                |units_3\n",
      "46                |46                |units_4\n",
      "200               |67                |tuner/epochs\n",
      "67                |0                 |tuner/initial_epoch\n",
      "1                 |1                 |tuner/bracket\n",
      "1                 |0                 |tuner/round\n",
      "0493              |None              |tuner/trial_id\n",
      "\n",
      "Epoch 68/200\n",
      "511/804 [==================>...........] - ETA: 0s - loss: 0.5731 - accuracy: 0.7236"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14876\\4018269289.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m tuner.search(X_train_scaled, y_train, epochs=200,\n\u001b[1;32m---> 20\u001b[1;33m              validation_data=(X_test_scaled, y_test))\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\justi\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras_tuner\\engine\\base_tuner.py\u001b[0m in \u001b[0;36msearch\u001b[1;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    181\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    182\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_trial_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 183\u001b[1;33m             \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    184\u001b[0m             \u001b[1;31m# `results` is None indicates user updated oracle in `run_trial()`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    185\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mresults\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\justi\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras_tuner\\tuners\\hyperband.py\u001b[0m in \u001b[0;36mrun_trial\u001b[1;34m(self, trial, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[0;32m    382\u001b[0m             \u001b[0mfit_kwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"epochs\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"tuner/epochs\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    383\u001b[0m             \u001b[0mfit_kwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"initial_epoch\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"tuner/initial_epoch\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 384\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mHyperband\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_trial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    385\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    386\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_build_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\justi\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\u001b[0m in \u001b[0;36mrun_trial\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    293\u001b[0m             \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m             \u001b[0mcopied_kwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"callbacks\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m             \u001b[0mobj_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_build_and_fit_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcopied_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m             \u001b[0mhistories\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\justi\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras_tuner\\engine\\tuner.py\u001b[0m in \u001b[0;36m_build_and_fit_model\u001b[1;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m         \u001b[0mhp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhyperparameters\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_try_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m         \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhypermodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m         tuner_utils.validate_trial_results(\n\u001b[0;32m    224\u001b[0m             \u001b[0mresults\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moracle\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"HyperModel.fit()\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\justi\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras_tuner\\engine\\hypermodel.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[0;32m    138\u001b[0m             \u001b[0mIf\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[0ma\u001b[0m \u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mit\u001b[0m \u001b[0mshould\u001b[0m \u001b[0mbe\u001b[0m \u001b[0mthe\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mobjective\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m         \"\"\"\n\u001b[1;32m--> 140\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\justi\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 65\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     66\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\justi\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1553\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_load_initial_step_from_ckpt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1554\u001b[0m                     )\n\u001b[1;32m-> 1555\u001b[1;33m                     \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1556\u001b[0m                         with tf.profiler.experimental.Trace(\n\u001b[0;32m   1557\u001b[0m                             \u001b[1;34m\"train\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\justi\\anaconda3\\envs\\mlenv\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36msteps\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1372\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1373\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1374\u001b[1;33m             \u001b[0moriginal_spe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1375\u001b[0m             can_run_full_execution = (\n\u001b[0;32m   1376\u001b[0m                 \u001b[0moriginal_spe\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\justi\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    635\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    636\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 637\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    638\u001b[0m     raise NotImplementedError(\n\u001b[0;32m    639\u001b[0m         \"numpy() is only available when eager execution is enabled.\")\n",
      "\u001b[1;32mc:\\Users\\justi\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36mread_value\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    723\u001b[0m     \"\"\"\n\u001b[0;32m    724\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Read\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 725\u001b[1;33m       \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_variable_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    726\u001b[0m     \u001b[1;31m# Return an identity so it can get placed on whatever device the context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m     \u001b[1;31m# specifies instead of the device where the variable is.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\justi\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36m_read_variable_op\u001b[1;34m(self, no_copy)\u001b[0m\n\u001b[0;32m    702\u001b[0m           \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_and_set_handle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mno_copy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 704\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_and_set_handle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mno_copy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    705\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\justi\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36mread_and_set_handle\u001b[1;34m(no_copy)\u001b[0m\n\u001b[0;32m    693\u001b[0m         \u001b[0mgen_resource_variable_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisable_copy_on_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    694\u001b[0m       result = gen_resource_variable_ops.read_variable_op(\n\u001b[1;32m--> 695\u001b[1;33m           self.handle, self._dtype)\n\u001b[0m\u001b[0;32m    696\u001b[0m       \u001b[0m_maybe_set_handle_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    697\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\justi\\anaconda3\\envs\\mlenv\\lib\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py\u001b[0m in \u001b[0;36mread_variable_op\u001b[1;34m(resource, dtype, name)\u001b[0m\n\u001b[0;32m    523\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    524\u001b[0m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[1;32m--> 525\u001b[1;33m         _ctx, \"ReadVariableOp\", name, resource, \"dtype\", dtype)\n\u001b[0m\u001b[0;32m    526\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Increased the function to increase hidden layer possibilities to 100 and layers to 5\n",
    "columns = ['USE_CASE_CommunityServ',\n",
    "           'USE_CASE_Heathcare',\n",
    "           'USE_CASE_Other',\n",
    "           'USE_CASE_Preservation',\n",
    "           'USE_CASE_ProductDev',\n",
    "           'ASK_BIN']\n",
    "\n",
    "optimizer_df = application_df.drop(columns=columns)\n",
    "X_train_scaled, X_test_scaled, y_train, y_test = df_trainer(optimizer_df)\n",
    "\n",
    "tuner = kt.Hyperband(\n",
    "    create_model,\n",
    "    objective=\"val_accuracy\",\n",
    "    max_epochs=200,\n",
    "    hyperband_iterations=2,\n",
    "    overwrite=True)\n",
    "\n",
    "tuner.search(X_train_scaled, y_train, epochs=0,\n",
    "             validation_data=(X_test_scaled, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268/268 - 0s - loss: 0.5595 - accuracy: 0.7280 - 310ms/epoch - 1ms/step\n",
      "Loss: 0.5595, Accuracy: 0.7280\n",
      "268/268 - 0s - loss: 0.5615 - accuracy: 0.7279 - 328ms/epoch - 1ms/step\n",
      "Loss: 0.5615, Accuracy: 0.7279\n",
      "268/268 - 0s - loss: 0.5587 - accuracy: 0.7278 - 315ms/epoch - 1ms/step\n",
      "Loss: 0.5587, Accuracy: 0.7278\n"
     ]
    }
   ],
   "source": [
    "top_model = tuner.get_best_models(3)\n",
    "for model in top_model:\n",
    "    loss, accuracy = model.evaluate(X_test_scaled, y_test, verbose=2)\n",
    "    print(f'Loss: {loss:.4f}, Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'activation': 'relu', 'first_units': 21, 'num_layers': 2, 'units_0': 71, 'units_1': 21, 'units_2': 11, 'units_3': 61, 'units_4': 46, 'tuner/epochs': 67, 'tuner/initial_epoch': 0, 'tuner/bracket': 1, 'tuner/round': 0}\n",
      "{'activation': 'relu', 'first_units': 56, 'num_layers': 3, 'units_0': 96, 'units_1': 76, 'units_2': 96, 'units_3': 31, 'units_4': 76, 'tuner/epochs': 200, 'tuner/initial_epoch': 67, 'tuner/bracket': 4, 'tuner/round': 4, 'tuner/trial_id': '0397'}\n",
      "{'activation': 'relu', 'first_units': 46, 'num_layers': 3, 'units_0': 31, 'units_1': 46, 'units_2': 86, 'units_3': 11, 'units_4': 21, 'tuner/epochs': 67, 'tuner/initial_epoch': 23, 'tuner/bracket': 3, 'tuner/round': 2, 'tuner/trial_id': '0200'}\n"
     ]
    }
   ],
   "source": [
    "top_hyper = tuner.get_best_hyperparameters(3)\n",
    "for param in top_hyper:\n",
    "    print(param.values)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Still unable to get higher than 73%, going to test Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "barf = BalancedRandomForestClassifier(n_estimators=100, random_state=512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7201702752975174"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the model\n",
    "barf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Calculated the balanced accuracy score\n",
    "y_pred = barf.predict(X_test_scaled)\n",
    "balanced_accuracy_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = application_df.IS_SUCCESSFUL\n",
    "X = application_df.drop(columns='IS_SUCCESSFUL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7292706687186423"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model\n",
    "barf.fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_pred = barf.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random forests was able to make a better prediction in 1.9 seconds. \n",
    "\n",
    "With the final data that were processed by the neural networks unscaled, so removing the user_type and ask bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['USE_CASE_CommunityServ',\n",
    "           'USE_CASE_Heathcare',\n",
    "           'USE_CASE_Other',\n",
    "           'USE_CASE_Preservation',\n",
    "           'USE_CASE_ProductDev',\n",
    "           'ASK_BIN', \n",
    "           'IS_SUCCESSFUL']\n",
    "\n",
    "y = application_df.IS_SUCCESSFUL\n",
    "X = application_df.drop(columns=columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7336909369730211"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model\n",
    "barf.fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_pred = barf.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And finally, using the unbinned data, the originally processed data, still removing the Use_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['USE_CASE_CommunityServ',\n",
    "           'USE_CASE_Heathcare',\n",
    "           'USE_CASE_Other',\n",
    "           'USE_CASE_Preservation',\n",
    "           'USE_CASE_ProductDev', \n",
    "           'IS_SUCCESSFUL']\n",
    "\n",
    "application_df = pd.read_csv(\"Resources/application_df.csv\")\n",
    "\n",
    "y = application_df.IS_SUCCESSFUL\n",
    "X = application_df.drop(columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7155946209206847"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model\n",
    "barf.fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_pred = barf.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance decreased - so the binned data performed better than the unbinned. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = ['USE_CASE_CommunityServ',\n",
    "           'USE_CASE_Heathcare',\n",
    "           'USE_CASE_Other',\n",
    "           'USE_CASE_Preservation',\n",
    "           'USE_CASE_ProductDev',\n",
    "           'IS_SUCCESSFUL', \n",
    "           'ASK_AMT']\n",
    "\n",
    "application_df = pd.read_csv(\"Resources/application_df.csv\")\n",
    "\n",
    "y = application_df.IS_SUCCESSFUL\n",
    "X = application_df.drop(columns=columns)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7338321660617974"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit model\n",
    "barf.fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_pred = barf.predict(X_test)\n",
    "balanced_accuracy_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "columns = ['USE_CASE_CommunityServ',\n",
    "           'USE_CASE_Heathcare',\n",
    "           'USE_CASE_Other',\n",
    "           'USE_CASE_Preservation',\n",
    "           'USE_CASE_ProductDev',\n",
    "           'IS_SUCCESSFUL',\n",
    "           'ASK_AMT']\n",
    "\n",
    "application_df = pd.read_csv(\"Resources/application_df.csv\")\n",
    "\n",
    "y = application_df.IS_SUCCESSFUL\n",
    "X = application_df.drop(columns=columns)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Prediction  Actual\n",
       "0           1       1\n",
       "1           1       0\n",
       "2           1       1\n",
       "3           0       1\n",
       "4           1       0"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape\n",
    "\n",
    "# Instantiate a linear SVM model\n",
    "from sklearn.svm import SVC\n",
    "model = SVC(kernel='linear')\n",
    "\n",
    "# Fit the data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the test data\n",
    "y_pred = model.predict(X_test)\n",
    "results = pd.DataFrame({\n",
    "    \"Prediction\": y_pred,\n",
    "    \"Actual\": y_test\n",
    "}).reset_index(drop=True)\n",
    "results.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7299125364431487"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2647, 1347],\n",
       "       [ 969, 3612]], dtype=int64)"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.66      0.70      3994\n",
      "           1       0.73      0.79      0.76      4581\n",
      "\n",
      "    accuracy                           0.73      8575\n",
      "   macro avg       0.73      0.73      0.73      8575\n",
      "weighted avg       0.73      0.73      0.73      8575\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7274635568513119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\justi\\anaconda3\\envs\\mlenv\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:818: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG,\n"
     ]
    }
   ],
   "source": [
    "classifier = LogisticRegression(solver='lbfgs', max_iter=200, random_state=1)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "y_predLM = classifier.predict(X_test)\n",
    "resultsLM = pd.DataFrame(\n",
    "    {\"Prediction\": y_pred, \"Actual\": y_test}).reset_index(drop=True)\n",
    "resultsLM.head()\n",
    "\n",
    "print(accuracy_score(y_test, y_predLM))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.68      0.70      3994\n",
      "           1       0.73      0.77      0.75      4581\n",
      "\n",
      "    accuracy                           0.73      8575\n",
      "   macro avg       0.73      0.72      0.72      8575\n",
      "weighted avg       0.73      0.73      0.73      8575\n",
      "\n"
     ]
    }
   ],
   "source": [
    "reportLM = classification_report(y_test, y_predLM)\n",
    "print(reportLM)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosted Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_scaled, X_test_scaled, y_train, y_test = df_trainer(optimizer_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate:  0.05\n",
      "Accuracy score (training): 0.722\n",
      "Accuracy score (validation): 0.715\n",
      "\n",
      "Learning rate:  0.1\n",
      "Accuracy score (training): 0.719\n",
      "Accuracy score (validation): 0.713\n",
      "\n",
      "Learning rate:  0.25\n",
      "Accuracy score (training): 0.724\n",
      "Accuracy score (validation): 0.716\n",
      "\n",
      "Learning rate:  0.5\n",
      "Accuracy score (training): 0.730\n",
      "Accuracy score (validation): 0.723\n",
      "\n",
      "Learning rate:  0.75\n",
      "Accuracy score (training): 0.732\n",
      "Accuracy score (validation): 0.723\n",
      "\n",
      "Learning rate:  1\n",
      "Accuracy score (training): 0.729\n",
      "Accuracy score (validation): 0.719\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "# Create a classifier object\n",
    "learning_rates = [0.05, 0.1, 0.25, 0.5, 0.75, 1]\n",
    "for learning_rate in learning_rates:\n",
    "    classifier = GradientBoostingClassifier(n_estimators=20,\n",
    "                                            learning_rate=learning_rate,\n",
    "                                            max_features=5,\n",
    "                                            max_depth=3,\n",
    "                                            random_state=0)\n",
    "\n",
    "    # Fit the model\n",
    "    classifier.fit(X_train_scaled, y_train)\n",
    "    print(\"Learning rate: \", learning_rate)\n",
    "\n",
    "    # Score the model\n",
    "    print(\"Accuracy score (training): {0:.3f}\".format(\n",
    "        classifier.score(\n",
    "            X_train_scaled,\n",
    "            y_train)))\n",
    "    print(\"Accuracy score (validation): {0:.3f}\".format(\n",
    "        classifier.score(\n",
    "            X_test_scaled,\n",
    "            y_test)))\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Prediction</th>\n",
       "      <th>Actual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29949</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26154</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30561</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8568</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4497</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8592</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19433</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2429</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33038</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5578</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26342</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21857</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7664</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15435</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20307</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28744</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6318</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23313</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21002</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22375</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Prediction  Actual\n",
       "29949           0       1\n",
       "26154           0       0\n",
       "30561           0       0\n",
       "8568            1       1\n",
       "4497            0       0\n",
       "8592            1       1\n",
       "19433           0       0\n",
       "2429            0       0\n",
       "33038           0       0\n",
       "5578            1       1\n",
       "26342           1       1\n",
       "21857           1       0\n",
       "7664            1       1\n",
       "15435           1       0\n",
       "20307           0       0\n",
       "28744           1       1\n",
       "6318            0       0\n",
       "23313           1       1\n",
       "21002           1       1\n",
       "22375           1       0"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Choose a learning rate and create classifier\n",
    "classifier = GradientBoostingClassifier(n_estimators=20,\n",
    "                                        learning_rate=0.5,\n",
    "                                        max_features=5,\n",
    "                                        max_depth=3,\n",
    "                                        random_state=0)\n",
    "\n",
    "# Fit the model\n",
    "classifier.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make Prediction\n",
    "predictions = classifier.predict(X_test_scaled)\n",
    "pd.DataFrame({\"Prediction\": predictions, \"Actual\": y_test}).head(20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Score : 0.7225655976676385\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "# Calculating the accuracy score\n",
    "acc_score = accuracy_score(y_test, predictions)\n",
    "print(f\"Accuracy Score : {acc_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted 0</th>\n",
       "      <th>Predicted 1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Actual 0</th>\n",
       "      <td>2595</td>\n",
       "      <td>1415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual 1</th>\n",
       "      <td>964</td>\n",
       "      <td>3601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted 0  Predicted 1\n",
       "Actual 0         2595         1415\n",
       "Actual 1          964         3601"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generate the confusion matrix\n",
    "cm = confusion_matrix(y_test, predictions)\n",
    "cm_df = pd.DataFrame(\n",
    "    cm, index=[\"Actual 0\", \"Actual 1\"],\n",
    "    columns=[\"Predicted 0\", \"Predicted 1\"]\n",
    ")\n",
    "\n",
    "# Displaying results\n",
    "display(cm_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.65      0.69      4010\n",
      "           1       0.72      0.79      0.75      4565\n",
      "\n",
      "    accuracy                           0.72      8575\n",
      "   macro avg       0.72      0.72      0.72      8575\n",
      "weighted avg       0.72      0.72      0.72      8575\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate classification report\n",
    "print(\"Classification Report\")\n",
    "print(classification_report(y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combination Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1: 18261, 0: 16038})"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Counter(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=512)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({0: 8417, 1: 3636})"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the SMOTEENN technique to perform combination sampling on the data\n",
    "# Count the resampled classes\n",
    "from imblearn.combine import SMOTEENN\n",
    "\n",
    "smote_enn = SMOTEENN(random_state=0)\n",
    "X_resampled, y_resampled = smote_enn.fit_resample(X, y)\n",
    "Counter(y_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=1)"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit a Logistic regression model using random undersampled data\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression(solver='lbfgs', random_state=1)\n",
    "model.fit(X_resampled, y_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3247,  747],\n",
       "       [2088, 2493]], dtype=int64)"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "confusion_matrix(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6785868881908323"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the Balanced Accuracy Score\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "balanced_accuracy_score(y_test, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   pre       rec       spe        f1       geo       iba       sup\n",
      "\n",
      "          0       0.61      0.81      0.54      0.70      0.67      0.45      3994\n",
      "          1       0.77      0.54      0.81      0.64      0.67      0.43      4581\n",
      "\n",
      "avg / total       0.69      0.67      0.69      0.66      0.67      0.44      8575\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print the imbalanced classification report\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "\n",
    "print(classification_report_imbalanced(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('mlenv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "55a128abeef29120eb7bd22a6a2e883184ae9f9178564f0df9c7c7d3d676105f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
